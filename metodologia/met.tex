\mychapter{Metodologia}
\label{Cap_3}

Este capítulo apresenta os materiais, métodos utilizados e desenvolvidos nessa pesquisa. O Sistema Computacional abordado está esquematizado na Seção 3.2, onde são mostradas a sua divisão em blocos e as inter-relações existentes entre eles. A Seção 3.3 contém algumas peculiaridades relevantes das implementações.

\section{Estudo e Desenvolvimento Inicial}
	
\subsection{Recursos e Estratégias Utilizadas no Desenvolvimento}

A plataforma adotada para a implementação do \emph{software} foi o Java, por ser um sistema bastante difundido e familiar, no entanto, nada impede que haja portabilidade do \emph{software} para outros sistemas operacionais, pois o Java consegue ser instalado rapidamente em todos os sistemas operacionais que estão no mercado. A versão utilizada foi a 8.21 para desenvolver a parte de negócios enquanto a interface gráfica foi utilizada o Java FX. A \emph{Integrated Development Environment} (IDE) de desenvolvimento do \emph{software} foi o NetBeans 8.2 da \emph{Oracle}. A linguagem de programação Java foi a escolhida para esse tipo de sistema, devido à facilidade na orientação a objeto, à capacidade de reuso do código, e a experiência de desenvolvimento nessa linguagem. 

Para o desenvolvimento do \emph{software} foi adotada uma metodologia ágil e o quadro de acompanhamento do desenvolvimento pode ser visualizado no GitHub. A implementação se deu através em testes, primeiramente focando em problemas menores e específicos, para, então, desenvolver soluções que satisfaçam os requisitos das novas \emph{sprints} em questão. O último passo foi estender o sistema para o atender outros tipos de problemas.

\subsection{Etapas do Desenvolvimento}

Inicialmente, objetivou-se a implementação do algoritmo empregado pelo sistema desenvolvido por (Towell \textit{et al.}, 1990) dividindo-a em duas sub-etapas distintas: A implementação relativa ao programa de extração de dados lógicos e a implementação da tradução em uma Rede Neural Artificial correspondente à teoria de domínio inicial.

Os testes se iniciaram com o desenvolvimento de métodos para a conversão de Linguagens Lógicas, apresentadas sob a forma de cláusulas Horn. Em seguida, a construção da RNAs e aplicação em problemas simples e específicos, para, logo em seguida generalizá-los. Na sequência, ocorreu a integração entre as duas partes, o sistema foi a aplicado a um problema mais extenso e geral do que os anteriores.

Na fase final do desenvolvimento, foi criado um sistema genérico de para gerar padrões de entradas e saídas de acordo com o as necessidades do usuário.

Os estudos realizados juntamente com a implementação desse projeto se deram ao longo de um ano e meio. Todo o processo que o sistema passou pode ser listado em 12 etapas que facilitaram o entendimento de todo o desenvolvimento. As etapas estão listadas pela sua ordem cronológica, nas quais se destacaram os respectivos enfoques e descrição, conforme segue:

\begin{itemize}
	
	\item \textbf{Etapa 1 (Padrões):} Estudo de Padrões de Projetos de \emph{software} para serem aplicados a sistema esse tipo de desenvolvimento.
	
	\item \textbf{Etapa 2 (RNA específica):} Implementações de RNAs simples, permitindo a primeira definição das técnicas de implementação de RNA a serem empregadas;  
	
	\item \textbf{Etapa 3 (\emph{Backpropagation}):} Estudo dos algoritmos de aprendizagem neural.
	
	\item \textbf{Etapa 4 (RNA genérica):} Versões mais aprimorada do programas de RNAs específicas, com refinamento das técnicas.
		
	\item \textbf{Etapa 5 (Interface gráfica):} Estudo preliminar para integrar todos os módulos para o gerenciamento do sistema KBANN em um ambiente computacional;
   
	\item \textbf{Etapa 6 (Algoritmo KBANN):} Estruturação das classes do sistema KBANN e desenvolvimento do método que engloba rotinas para o processamento da sintaxe de textos;

	\item \textbf{Etapa 7 (Conversão de dados):} Formatação dos dados a serem aplicados em uma RNA específica, definição dos formatos dos arquivos;

	\item \textbf{Etapa 8 (Algoritmo KBANN):} Aprimoramento dos programas anteriores permitindo a inserção das regras aplicáveis de forma genérica, segundo o algoritmo KBANN;

	\item \textbf{Etapa 9 (Algoritmo KBANN):} Aplicação do algoritmo KBANN a exemplos específicos;

	\item \textbf{Etapa 10 (Algoritmo TopGen):} Implementação do algoritmo TopGen para gerar novas redes;
	
	\item \textbf{Etapa 11 (Algoritmo TopGen):} Comparação entre RNAs com e sem o emprego do algoritmo TopGen;
		
	\item \textbf{Etapa 12 (Algoritmo KBANN e TopGen):} Testes das RNAs com utilização do algoritmo KBANN;
			
	
\end{itemize}

As etapas iniciais (1 a 5) tiveram fundamental importância no trabalho, pois serviram para a fundamentação dos conceitos básicos de um sistema híbrido e a base para um bom desenvolvimento. Nas etapas 2 e 4 foram realizados estudos que definiu a forma mais apropriada de como a interface deveria ser implementada. As etapas 3, 6 e 9 relacionam as implementações aplicadas a exemplos específicos. As etapas 7, 8, 10, 11 e 12 focam o algoritmo KBANN, TopGen e suas aplicações. 

\subsection{Implementações Preliminares}	

Algumas implementações básicas foram necessárias para se adquirir experiência. O conhecimento adquirido com essas implementações ajudou a composição dos blocos das implementações subsequentes. Pode-se destacar abaixo as duas principais implementações iniciais:

(a) Extração de regras lógicas.

(b) Utilização de exemplos variados para o treinamento das RNAs. 

\subsubsection{Leitura de Dados Simbólicos}

A leitura de dados simbólicos serviu de base para a implementação do algoritmo de conversão KBANN. A execução, o acompanhamento e os testes dessa implementação permitiram verificar a tradução de uma base de regras iniciais em uma rede neural de KBANN.
A Figura \ref{fig:visualizacaoGrafo} é a representação final das regras lógicas contidas nas cláusulas lógicas mostradas abaixo na forma de cláusulas de Horn. A partir desse conjunto de símbolos, foram obtidas as estruturas das RNAs similares às da Figura \ref{fig:visualizacaoGrafo}, aplicando-se a elas os cálculos requeridos pelo algoritmo, tais como a determinação dos pesos inciais, bias, taxa de aprendizado da rede e o erro aceitável.

\centerline{$A$ :- $B$,  $¬C$} 
\centerline{$B$ :- $D$, $¬F$, $G$} 
\centerline{$B$ :- $D$, $F$, $I$} 
\centerline{$C$ :- $H$, $J$, $K$} 

Cada instrução acima, representa uma regra do domínio da teoria, a união delas implica nas regras que definem um problema. Para melhor entendimento, as cláusulas no formato de Prolog podem ser lidas da seguinte maneira: ao lado esquerdo ficam os consequentes, ou seja, as implicações que são geradas pelos seus antecedentes (lado direito). Os antecedentes são as condições necessárias para ativar um consequente, esses, são separados por vírgulas (,) quando se quer definir que ambos os consequentes precisam ser ativados para sair uma determinada resposta do seu respectivo consequente da regra.

\begin{figure}[H] 
	\begin{center}
		\caption{Representação de uma RNA a partir da base de regras.}
		\includegraphics[scale=0.5]{imagens/visualizacaoGrafo.png}
		\label{fig:visualizacaoGrafo}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}


\subsubsection{Redes Neurais Artificiais simples}	

Os primeiros programas desenvolvidos nesse trabalho utilizavam a topologia básica da RNA com três camadas e com poucos neurônios por camada (por exemplo: 5 x 3 x 1 ou 2 x 2 x 1). Nesse caso, pretendia-se fazer somente o treinamento da RNA, verificação de cálculos e teste estrutural da arquitetura e do algoritmo de treinamento.

Alguns exemplos simples foram utilizados, como o de reconhecimento e classificação de dados (padrões sensíveis à RNA). Na classificação de dados, como por exemplo, foi utilizado as regras determinadas logo acima para os testes inicias. Além disso, os mesmos testes foram validados no \emph{Matlab}, tanto usando o \emph{Neural Network ToolBox} de redes neurais que é disponibilizado no \emph{software}, como também, realizando passo a passo as operações matemáticas

As cincos regras acima descrevem inicialmente o modelo daquele problema em específico. Assim como foi feito no TopGen, foram retiradas algumas regras do domínio teórico inicial, e em seguida realizando o treinamento e a validação. Foi possível notar que o KBANN ainda consegue classificar boa parte dos dados, mesmo não tendo um domínio completo do problema. Esse teste foi feito justamente para provar o que Towell \textit{et al.} (1990) comentou em seu trabalho, que não é necessário saber a fundo sobre problema. Apesar da sua boa classificação contendo 3 (três) regras das 5 (cinco) originais Variações desse modelo poderiam servir de exemplo para o treinamento da RNA.

A criação de uma interface para entrada de dados fez-se necessária com a migração para programas mais genéricos. A solução mais imediata foi a adoção de arquivos formatados contendo um conjunto de definições, que são alteráveis no programa antes da sua execução.

\subsection{O Sistema Desenvolvido}	

O enfoque principal do sistema desenvolvido foi a implementação do algoritmo de conversão unidirecional do sistema KBANN estendido por modalidades. A modelagem da interface utilizada iniciou-se a partir do desenvolvimento de um editor de arquivos, com o objetivo de edição e salvamento de arquivos utilizados pelo programa. Essa interface também permite que se criem novos arquivos de informações.

\subsection{Aspectos Internos do Sistema}

\subsubsection{Classes que Compõem o Programa}

A Figura \ref{fig:diagramaClasses} apresenta um esquema das classes nas quais o ambiente computacional teve o seu desenvolvimento baseado. A classe que controla toda a aplicação é a ControllerGrafo. Ela recebe todas as requisições oriundas da interface gráfica e delega para outras classes algumas ações necessárias. Por exemplo, a classe  ControllerRegras realiza o tratamento da programação em linguagem lógica, conforme as opções que lhe são passadas.
Pensando em futuras expansões do projeto, foram criadas classes e módulos que poderão se acoplar facilmente a novas classes. A classe ModelGrafo que representa a rede neural, por exemplo pode receber novos tipos de neurônios ou conexões de forma bastante simples.

\begin{figure}[H] 
	\begin{center}
		\caption{Representação parcial do diagrama de classes do sistema.}
		\includegraphics[scale=0.5]{imagens/diagramaClasses.png}
		\label{fig:diagramaClasses}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}


\subsubsection{Casos de Uso Previstos}

A Figura \ref{fig:diagramaCasosUso} contém alguns casos mais comuns de uso do ambiente computacional. Um especialista do conhecimento pode valer-se desse ambiente para aplicá-lo a um problema específico. O objetivo de aplicação pode ser: o aumento na abrangência de regras associadas ao conhecimento inicial do especialista. Cada um dos casos de uso se refere a uma etapa existente neste ciclo, proposto para o aprimoramento das regras provenientes do conhecimento.

\begin{figure}[H] 
	\begin{center}
		\caption{Diagrama de Casos de Uso.}
		\includegraphics[scale=0.5]{imagens/diagramaCasoUso.png}
		\label{fig:diagramaCasosUso}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}

\subsubsection{Sequência de Eventos}

O diagrama de classes da Figura \ref{fig:diagramaSequencia} aponta para a sequência de operações iniciadas pelo usuário, que basicamente, interage através da configuração contida nos arquivos e na interface. O \emph{software} realiza uma varredura do arquivo que contém as informações necessárias ao desenvolvimento de seus processos.

\begin{figure}[H] 
	\begin{center}
		\caption{Diagrama de Sequência.}
		\includegraphics[scale=0.5]{imagens/diagramaSequencia.png}
		\label{fig:diagramaSequencia}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}

Como ilustra a Figura \ref{fig:diagramaSequencia}, o \emph{software} interno atua na modificação da estrutura da RNA geral, quer seja pelo estabelecimento da sua topologia, quer na alteração dessa em consequência da aprendizagem. Uma vez que as operações estejam encerradas, o usuário pode consultar os arquivos produzidos e verificar os resultados.

Os passos à execução do programa podem ser resumidos dessa forma:

1. Seleção dos algoritmos, das operações, dos arquivos de dados.

2. A partir dos arquivos de informações inseridos, um conjunto de dados internos de trabalho é produzido pelo programa. Nesse conjunto de dados, podem ser lidos átomos, os mundos aos quais eles pertencem, as devidas posições e recursividades entre eles. 

3. Os cálculos são executados baseados nas informações do passo 2 e se estabelecem a topologia inicial da RNA e suas sub-RNAs, havendo o seu acompanhamento. 

4. Opcionalmente, novas informações podem ser obtidas a partir da leitura de exemplos, durante o aprendizado, alterando e preparando as RNAs aos processos de inferências. 

5. Inicia-se a etapa de dedução lógica. Busca-se a computação convergente do programa, que se reflete na procura da estabilidade do sistema.

\subsubsection{Processos do Sistema}

Na Figura XX, pode-se acompanhar, de outra forma, as etapas apresentadas nos casos de uso do sistema (Figura \ref{fig:diagramaCasosUso}). Também tem-se a visão interna da sequência de processos e a atividade de inter-relação entre as classes (Figura \ref{fig:diagramaClasses}). Primeiramente, um programa em linguagem lógica será inserido e, conforme a configuração, ocorre o seu processamento inicial.

Existem dois processos relativos à estrutura que entram em operação após a leitura dos dados iniciais: as RNAs são instanciadas e as suas topologias iniciais são fixadas. Logo após, iniciam-se os processos de aprendizagem das RNAs, que podem alterar a forma original da estrutura da rede geral.

Após o processamento da programação, instanciam-se as RNAs correspondentes, assim como os cálculos relativos ao algoritmo em operação. A etapa de aprendizagem das RNAs é executada logo em seguida, finalizando pela obtenção de resultados. Os resultados gerados pelo programa são as RNAs após o processos de aprendizagem e o percentual de acerto obtido individualmente pelas RNAs.

\subsection{Descrição da Interface}

A interface também contém um menu para seleção do algoritmo a ser utilizado, assim como as suas opções de operação dos algoritmos. A aparência da interface está ilustrada pela Figura \ref{fig:telaPrincipal}. A descrição da interface segue nessa seção.

\begin{figure}[H] 
	\begin{center}
		\caption{Tela principal do sistema.}
		\includegraphics[scale=0.5]{imagens/telaPrincipal.png}
		\label{fig:telaPrincipal}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}


\subsubsection{Painel de Edição}

Os arquivos carregados no programa pode ser visualizados na tela de edição, conforme a Figura \ref{fig:editorRegras}

1. A planta inicial, que informa a teoria de domínio que deseja-se representar inicialmente para um possível refinamento.

2. A planta final, que possui o domínio completo e correto do problema.

Esses dois arquivos são abertos e acessados diretamente no painel interno da interface. Não existe restrição quanto ao tipo de arquivo a ser editado. 

\begin{figure}[H] 
	\begin{center}
		\caption{Tela de edição de regras.}
		\includegraphics[scale=0.5]{imagens/editorRegras.png}
		\label{fig:editorRegras}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}

\subsubsection{Barra do Menu}

A barra de menu da interface facilita algumas operações de edição e execução dos programas. 

\subsubsection{Menu Lateral}

A interface também conta com menu \emph{according} localizada nas laterias da janela principal que serve para o acompanhamento do andamento das operações. Esse menu extra possibilita ao usuário identificar o que foi lido do arquivo que contém as regras, saber o resultado final após o treinamento e o TopGen e identificar os níveis (camadas) por cor, as quais os neurônios fazem parte.

\subsection{Considerações sobre as implementações}	

A maioria dos programas desenvolvidos empregaram as RNAs com o seu aprendizado executado por meio do algoritmo de retro-propagação. A escolha desse algoritmo deveu-se à sua utilização no sistema KBANN, possibilitando a comparação de resultados. Os algoritmos que definiram as topologias de RNAs empregadas foram consequência da evolução natural das técnicas de programação.
Os valores de saída e as sinapses da RNA foram implementados por variáveis contidas nas classes Neurônio e Arestas. Quando se deseja acessar o valor contido em um neurônio específico, é utilizado um \emph{HashMap} que possui todos os objetos neurônios. Dentro de cada neurônio existe os campos que identifica se ele é da camada de entrada, saída ou de qual camada intermediária ele faz parte. Na Figura \ref{fig:diagramaClasses}, é possível ver a representação dessas estruturas com as quais pode-se acessar quaisquer valor desejado no grafo neural construído.

\subsection{Testes do Sistema}

Para validação do sistema desenvolvido, foi utilizado o \emph{software} \emph{Matlab} como referência, devido as suas diversas ferramentas amplamente testadas pela comunidade científica. Para realização do teste, foi necessário criar um exemplo de rede MLP de acordo com o que podia ser modelado no \emph{Matlab}. Na Figura \ref{fig:RedeMatlabEstrutura}, a sua estrutura da rede MLP pode ser vista após a definição do problema. Esse teste teve como intenção apenas que os resultados encontrados no programa fossem relativamente parecidos ou próximos do que o \emph{Matlab} gerou. 

\begin{figure}[H] 
	\begin{center}
		\caption{Topologia da rede MLP no \emph{Matlab}.}
		\includegraphics[scale=0.5]{imagens/RedeMatlabEstrutura.png}
		\label{fig:RedeMatlabEstrutura}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}

Como pode ser vista na Figura \ref{fig:RedeMatlabEstrutura}, a rede ser treinada é uma MLP que possui 4 neurônios na sua camada de entrada, 2 neurônios em sua única camada oculta e uma única classe de representação na camada de saída. O problema apresentado a essa rede é de padrão lógico, ou seja, informações binárias. Os dados contidos nesse padrão correspondem ao domínio completo, ou seja, como realmente funciona o sistema. Nesse teste foi considerado que a MLP não iria possuir em sua topologia todas as regras que definem o problema, sendo assim, foram retiradas 2 regras do domínio apresentado, o que de fato, se espera que gerasse alguns erros na rede ou até mesmo não convergir.

\begin{figure}[H] 
	\begin{center}
		\caption{Parâmetros após treinamento da Rede MLP no \emph{Matlab}.}
		\includegraphics[scale=0.5]{imagens/RedeMatlabTreinada.png}
		\label{fig:RedeMatlabTreinada}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}

Pelo o que foi apresentado na Figura \ref{fig:RedeMatlabTreinada}, pode-se observar que o \emph{Neural Network ToolBox}  do \emph{Matlab} levou 10.000 épocas para finalizar o problema, ou seja, o erro de treinamento ou o erro de validação aceitável não foi obtido, sendo necessário utilizar a quantidade de épocas totais para finalizar o treinamento. Nesse exemplo, foi utilizado o algoritmo de \emph{backpropagation} e a função de ativação dos neurônios escolhida foi a sigmoide Outros parâmetros como taxa de aprendizagem, erro aceitável (goal) e o tempo para simulação podem ser verificados na Figura \ref{fig:redeMatlabParametros}.

\begin{figure}[H] 
	\begin{center}
		\caption{Parâmetros da rede MLP treinada.}
		\includegraphics[scale=0.5]{imagens/redeMatlabParametros.png}
		\label{fig:redeMatlabParametros}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}

As duas últimas Figuras (\ref{fig:GraficoErroMatlab} e \ref{fig:errosMatlab}) servem para afirmar o baixo aprendizado pela rede MLP para o exemplo fornecido. O erro aceitável ficou longe de ser alcançado e as saídas finais da rede tiveram valores sempre mantidos acima de 0.5, o que é um erro bastante grande. Para um melhor entendimento sobre o resultado gerados pela Figura \ref{fig:errosMatlab}, será discutido um passo dos vários que foram feitos para o treinamento. A Figura \ref{fig:errosMatlab} possui as 16 saídas para as 16 amostradas que foram apresentadas a rede neural. A primeira amostra foi a entrada 0 0 0 0 e sua saída deveria ser 0, mas nesse caso a rede considerou que o "certo" para esse treinamento é 0.73587, sendo necessário um ajuste de de -0.73587 para corresponder com a realidade. Todos os demais dados apresentados para treinamento e validação, podem ser vistos na \ref{fig:resultado1SemTopgen}. 

\begin{figure}[H] 
	\begin{center}
		\caption{Gráfico do erro de treinamento, validação e teste.}
		\includegraphics[scale=0.5]{imagens/GraficoErroMatlab.png}
		\label{fig:GraficoErroMatlab}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}

\begin{figure}[H] 
	\begin{center}
		\caption{Resultados gerados na saída da rede.}
		\includegraphics[scale=0.5]{imagens/errosMatlab.png}
		\label{fig:errosMatlab}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}

O mesmo teste considerando as mesmas configurações da rede (taxa de aprendizado, função de ativação) e o conjunto de dados foram realizados pelo sistema desenvolvido utilizando apenas o KBANN e em seguida o KBANN com o TopGen. Na Figura \ref{fig:resultado1SemTopgen} a rede KBANN conseguiu classificar corretamente todos os dados apresentados em sua saída (A), mas obteve dois erros em uma saída intermediária (B), onde obteve dois falsos negativos. Esses erros já eram esperados devido a retirada de duas regras do domínio que rege esse problema.

\begin{figure}[H] 
	\begin{center}
		\caption{Resultados gerados na saída da rede apenas com KBANN.}
		\includegraphics[scale=0.5]{imagens/resultado1_semTopGen.png}
		\label{fig:resultado1SemTopgen}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}

Na Figura \ref{fig:resultado1ComTopgen}, pode-se observar que o erro em todas as saídas intermediárias (B e C), assim como a saída principal da rede (A) tiveram erro zero, ou seja, para todos os dados apresentados, foram classificados corretamente sem nenhuma execção, mostrando assim, uma boa eficácia do sistema. Para se conseguir esse feito, foram necessários adicionar a rede original de KBANN, dois neurônios, o TG1B e TG2B (ver Figura \ref{fig:resultado1RedeComTopgen}),  o motivo dessa adição pode ser vista na seção (2.3). Esse neurônios fizeram com que os erros da saída intermediária (B) fossem zerados sem modificar o aprendizado obtido em outros pontos da rede.

\begin{figure}[H] 
	\begin{center}
		\caption{Resultados gerados na saída da rede com KBANN e TopGen.}
		\includegraphics[scale=0.5]{imagens/resultado1_comTopGen.png}
		\label{fig:resultado1ComTopgen}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}

\begin{figure}[H] 
	\begin{center}
		\caption{Rede gerada com os novos neurônios a partir do TopGen.}
		\includegraphics[scale=0.5]{imagens/resultado1_RedeComToGen.png}
		\label{fig:resultado1RedeComTopgen}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}


