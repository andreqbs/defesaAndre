\mychapter{Metodologia}
\label{Cap_3}

Esse capítulo apresenta os materiais, métodos utilizados e desenvolvidos nessa pesquisa. O sistema computacional abordado está esquematizado na Seção 3.2, na qual são mostradas a sua divisão em blocos e as inter-relações existentes entre eles. A Seção 3.3 contém algumas peculiaridades relevantes das implementações.

\section{Estudo e Desenvolvimento Inicial}
	
\subsection{Recursos e Estratégias Utilizadas no Desenvolvimento}

A plataforma adotada para a implementação do \emph{software} foi o Java, por ser um sistema bastante difundido e familiar, no entanto, nada impede que haja portabilidade do \emph{software} para outros sistemas operacionais, pois o Java consegue ser instalado rapidamente em todos os sistemas operacionais que estão no mercado. Foi utilizada a versão 8.21 para desenvolver o modelo de negócios enquanto a interface gráfica foi utilizada o Java FX. A \emph{Integrated Development Environment} (IDE) de desenvolvimento do \emph{software} foi o NetBeans 8.2 da \emph{Oracle}. A linguagem de programação Java foi a escolhida para esse tipo de sistema, devido à facilidade na orientação a objeto, à capacidade de reuso do código, e a experiência de desenvolvimento nessa linguagem. 

Para o desenvolvimento do \emph{software} foi adotada uma metodologia ágil e o quadro de acompanhamento do desenvolvimento pode ser visualizado no repositório criado \emph{GitHub}. A implementação se deu através de testes, primeiramente focando em problemas menores e específicos, para, então, desenvolver soluções que satisfaçam os requisitos das novas \emph{sprints} em questão. O último passo foi estender o sistema para o atender outros tipos de problemas.

\subsection{Etapas do Desenvolvimento}

Inicialmente, objetivou-se a implementação do algoritmo empregado pelo sistema desenvolvido por Towell \textit{et al.} (1990) dividindo-a em duas subetapas distintas: A implementação relativa ao programa de extração de dados lógicos e a implementação da tradução em uma RNA correspondente à teoria de domínio inicial.

Os testes iniciaram com o desenvolvimento de métodos para a conversão de Linguagens Lógicas, apresentadas sob a forma de cláusulas Horn. Em seguida, a construção da RNAs e aplicação em problemas simples e específicos, para, logo em seguida generalizá-los. Na sequência, ocorreu a integração entre as duas partes, o sistema foi a aplicado a um problema mais extenso e geral que os anteriores.

Na fase final do desenvolvimento, foi criado um sistema genérico de para gerar padrões de entradas e saídas de acordo com o as necessidades do usuário.

O processo de produção do sistema pode ser listado em 12 etapas que facilitaram o entendimento de todo o desenvolvimento. As etapas estão listadas pela sua ordem cronológica, nas quais se destacaram os respectivos enfoques e descrição, conforme segue:

\begin{itemize}
	
	\item \textbf{Etapa 1 (Padrões de Software):} Estudo de padrões de projetos de \emph{software} para serem aplicados a esse tipo de sistema.
	
	\item \textbf{Etapa 2 (RNA específica):} Implementações de RNAs simples, permitindo a primeira definição das técnicas de implementação de RNA a serem empregadas;  
	
	\item \textbf{Etapa 3 (\emph{Backpropagation}):} Estudo dos algoritmos de aprendizagem neural.
	
	\item \textbf{Etapa 4 (RNA genérica):} Versões mais aprimoradas do programas de RNAs específicas, com refinamento das técnicas.
		
	\item \textbf{Etapa 5 (Interface gráfica):} Estudo preliminar para integrar todos os módulos para o gerenciamento do sistema KBANN em um ambiente computacional;
   
	\item \textbf{Etapa 6 (Algoritmo KBANN):} Estruturação das classes do sistema KBANN e desenvolvimento do método que engloba rotinas para o processamento da sintaxe de textos;

	\item \textbf{Etapa 7 (Conversão de dados):} Formatação dos dados a serem aplicados em uma RNA específica e formatação dos arquivos a serem lidos;

	\item \textbf{Etapa 8 (Algoritmo KBANN):} Aprimoramento dos programas anteriores permitindo a inserção das regras aplicáveis de forma genérica, segundo o algoritmo KBANN;

	\item \textbf{Etapa 9 (Algoritmo KBANN):} Aplicação do algoritmo KBANN a exemplos específicos;

	\item \textbf{Etapa 10 (Algoritmo TopGen):} Implementação do algoritmo TopGen para gerar novas redes;
	
	\item \textbf{Etapa 11 (Tabuleiro de xadrez):} Implementação do tabuleiro de xadrez e seus respectivos métodos para extração de informações que serviram de entrada para a rede neural;
	
	\item \textbf{Etapa 12 (Algoritmo TopGen):} Comparação entre RNAs com e sem o emprego do algoritmo TopGen.
	
\end{itemize}

As etapas iniciais (1 a 5) foram fundamentais no trabalho, pois foi a base para a fundamentação dos conceitos básicos de um sistema híbrido e a base para um bom desenvolvimento do \emph{software}. Nas etapas 2 e 4 foram realizados estudos que definiram a forma mais apropriada de como a interface deveria ser implementada. As etapas 3, 6 e 9 relacionam as implementações aplicadas a exemplos específicos. As etapas 7, 8, 10, 11 e 12 foram destinadas aos algoritmos, KBANN e TopGen, além de suas aplicações. 

\subsection{Implementações Preliminares}	

Algumas implementações básicas foram necessárias para se adquirir experiência. O conhecimento adquirido com essas implementações ajudou a composição dos blocos das implementações subsequentes. Pode-se destacar abaixo as duas principais implementações iniciais:

(a) Extração de regras lógicas.

(b) Utilização de exemplos variados para o treinamento das RNAs. 

\subsubsection{Leitura de Dados Simbólicos}

A interpretação dos dados simbólicos é a base para implementação do algoritmo de conversão do KBANN. As informações são extraídas do arquivo base e então é gerado uma rede neural.
A Figura \ref{fig:visualizacaoGrafo} é a representação final das regras lógicas contidas nas cláusulas lógicas mostradas abaixo na forma de cláusulas de \emph{Horn}. A partir desse conjunto de símbolos, foram obtidas as estruturas das RNAs similares às da Figura \ref{fig:visualizacaoGrafo}, aplicando-se a elas os cálculos requeridos pelo algoritmo, tais como a determinação dos pesos iniciais, bias, taxa de aprendizado da rede e o erro aceitável. A seguir será apresentado um exemplo de um conjunto de regras iniciais e sua tradução em uma rede neural.

\centerline{$A$ :- $B$,  $¬C$} 
\centerline{$B$ :- $D$, $¬F$, $G$} 
\centerline{$B$ :- $D$, $F$, $I$} 
\centerline{$C$ :- $H$, $J$, $K$} 

\begin{figure}[H] 
	\begin{center}
		\caption{Representação de uma RNA a partir da base de regras}
		\includegraphics[scale=0.5]{imagens/visualizacaoGrafo.png}
		\label{fig:visualizacaoGrafo}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}

Cada instrução acima representa uma regra do domínio da teoria, a união delas implica nas regras que definem um problema. Para melhor entendimento, as cláusulas no formato de Prolog podem ser lidas da seguinte maneira: ao lado esquerdo ficam os consequentes, ou seja, as implicações que são geradas pelos seus antecedentes (lado direito). Os antecedentes são as condições necessárias para ativar um consequente e esses são separados por vírgulas (,) quando se quer definir que ambos os antecedentes precisam estar ativados para sair uma determinada resposta do seu respectivo consequente da regra. Quando um antecedente um é negado ($\neg$), o peso sináptico da ligação entre os neurônios será negativo. Essa foi uma maneira encontrada por Towell (1990) para que a rede neural possa receber entradas contrárias à aquelas que ativam os neurônios permitindo que eles sejam ativados quando houver um antecedente negado.

\subsubsection{Redes Neurais Artificiais Simples}	

Os primeiros programas desenvolvidos nesse trabalho utilizavam a topologia básica da RNA com três camadas e com poucos neurônios por camada (por exemplo: 5 x 3 x 1 ou 2 x 2 x 1). Nesse caso, foi realizado somente o treinamento da RNA, verificação de cálculos e teste estrutural da arquitetura e do algoritmo de treinamento.

Alguns exemplos simples foram utilizados, como: o reconhecimento e a classificação de dados (padrões sensíveis à RNA). Além disso, os mesmos testes foram validados no \emph{Matlab}, tanto utilizando o \emph{Neural Network ToolBox} de redes neurais que é disponibilizado no \emph{software}, como também, realizando passo a passo as operações matemáticas

O conjunto de regras iniciais citadas no item 3.1.3.1 descrevem inicialmente o modelo do problema estudado. Da mesma forma como foi feito no TopGen, foram retiradas algumas regras do domínio teórico inicial, e em seguida foi realizado o treinamento e a validação. Foi possível observar que o KBANN consegue classificar boa parte dos dados, mesmo não possuindo um domínio completo do problema. O teste foi realizado para comprovar o que foi discutido no trabalho de Towell \textit{et al.} (1990). 

A criação de uma interface para entrada de dados fez-se necessária com a migração para programas mais genéricos. A solução mais imediata foi a adoção de arquivos formatados contendo um conjunto de definições, que são alteráveis no programa antes da sua execução.

\subsection{O Sistema Desenvolvido}	

O enfoque principal do trabalho desenvolvido foi a implementação de \emph{framework} capaz de agregar as principais características de dois algoritmos importantes do meio neuro-simbólico, o KBANN e o TopGen. O primeiro realiza a conversão unidirecional de regras no formato de cláusulas Horn em uma rede neural com conhecimento prévio, enquanto o segundo permite a adição de novos conhecimentos na rede gerada a partir de KBANN, sem causar danos aos conhecimentos já adquiridos. Para gerar uma nova rede , o sistema é capaz de ler um arquivo TXT com regras já estabelicidas por um especialista ou é possível criá-las dentro do \emph{software}. O \emph{framework} também permite exibir de forma gráfica a rede inicial e final de duas formas: em círculo ou por hierarquia de nível. Cada camada da rede é identificada por uma cor e essa pode ser visualizada pelo usuário na aba legendas dentro do sistema. Para realizar o treinamento da rede neural utilizando o algoritmo do \emph{bakcpropagation}, o sistema possui em sua interface campos configuráveis, como: taxa de aprendizagem, taxa de momento, número de épocas e erro aceitável. Quando os campos são preenchidos, o usuário poderá realizar quantos treinamentos desejar. Por fim, é possível exportar em um arquivo TXT uma lista contendo a quantidade de erros (falsos positivos e negativos) de cada neurônio contido na rede, permitindo assim avaliar a necessidade de adicionar novos neurônios para ajustar a rede neural.

\subsection{Aspectos Internos do Sistema}

\subsubsection{Classes que Compõem o Programa}

A Figura \ref{fig:diagramaClasses} apresenta um esquema das classes nas quais o ambiente computacional teve o seu desenvolvimento. A principal classe, a que controla todos os processos da aplicação é a \emph{ControllerGrafo}. Essa recebe todas as requisições oriundas da interface gráfica e delega para outras classes as ações necessárias. Por exemplo, a classe \emph{ControllerRegras} realiza o tratamento das regras iniciais gerando objetos do tipo \emph{ModelRegra} que serão utilizados para construir a rede neural.
Para modelar e representar a estrutura de uma rede neural, foi implementada a classe \emph{ModelGrafo}. Essa é composta por outras duas classes que ajudam na representação da rede, no caso, as classes \emph{ModelNeuronio} e \emph{ModelAresta}. A classe \emph{Treinamento} foi criada separadamente para permitir a adição de novos treinamentos ao sistema, por enquanto, apenas o algoritmo \emph{backpropagation} foi implementado. A classe \emph{TopGen} contém o algoritmo que permite a adição de novos conhecimentos na rede neural, além disso, ela possui a capacidade de calcular e exportar os erros contidos em cada neurônio da rede. Por fim, a classe Xadrez representa o modelo do problema em questão, além de gerar as entradas e respectivas saídas para realizar o treinamento.

\begin{figure}[H] 
	\begin{center}
		\caption{Diagrama de classes do sistema}
		\includegraphics[scale=0.5]{imagens/diagramaClasses.png}
		\label{fig:diagramaClasses}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}

\subsubsection{Sequência de Eventos}

O diagrama de sequência da (Figura \ref{fig:diagramaSequencia}) aponta para a sequência de operações iniciadas pelo usuário, que basicamente, interage através da configuração contida nos arquivos e na interface. O \emph{software} realiza uma varredura do arquivo que contém as informações necessárias ao desenvolvimento de seus processos.

\begin{figure}[H] 
	\begin{center}
		\caption{Diagrama de Sequência}
		\includegraphics[scale=0.5]{imagens/diagramaSequencia.png}
		\label{fig:diagramaSequencia}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}

Como ilustra a Figura \ref{fig:diagramaSequencia}, o \emph{software} interno atua na modificação da estrutura da RNA geral, quer seja pelo estabelecimento da sua topologia, quer na alteração dessa em consequência da aprendizagem. Uma vez que as operações estejam encerradas, o usuário pode consultar os arquivos produzidos e verificar os resultados.

Os passos para a execução do programa podem ser resumidos dessa forma:

1. Importação do arquivo contendo as regras iniciais;

2. Extração de regras pelo programa para gerar a rede neural inicial;

3. Configuração do sistema para realizar o treinamento;

4. Realizar o treinamento e verificar se o erro aceitável foi alcançado;

5. Aplicar o teste de Falsos Positivos e Negativos na rede gerada.

6. Gerar novas redes para correção de erros da saída da rede neural.

\subsection{Descrição da Interface}

A interface também contém um menu para seleção do algoritmo a ser utilizado, assim como as suas opções de operação dos algoritmos. A aparência da interface está ilustrada pela Figura \ref{fig:telaPrincipal}. A descrição da interface segue nessa seção.

\begin{figure}[H] 
	\begin{center}
		\caption{Tela principal do sistema}
		\includegraphics[scale=0.5]{imagens/telaPrincipal.png}
		\label{fig:telaPrincipal}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}


\subsubsection{Painel de Edição}

Os arquivos carregados no programa podem ser visualizados na tela de edição, conforme a Figura \ref{fig:editorRegras}.

\begin{figure}[H] 
	\begin{center}
		\caption{Tela de edição de regras}
		\includegraphics[scale=0.5]{imagens/editorRegras.png}
		\label{fig:editorRegras}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}

As entradas de dados podem ser realizadas de duas maneiras:

1. A planta inicial, que informa a teoria de domínio que deseja-se representar inicialmente para um possível refinamento.

2. A planta final, que possui o domínio completo e correto do problema.

Esses dois arquivos são abertos e acessados diretamente no painel interno da interface. Não existe restrição quanto ao tipo de arquivo a ser editado. 

\subsubsection{Barra do Menu}

A barra de menu da interface facilita algumas operações de edição e execução dos programas. 

\subsubsection{Menu Lateral}

A interface também possui menu \emph{according} localizada nas laterais da janela principal que serve para o acompanhamento do andamento das operações. Esse menu extra possibilita ao usuário identificar o que foi lido do arquivo que contém as regras, saber o resultado final após o treinamento e o TopGen e identificar os níveis (camadas) por cor, as quais os neurônios fazem parte.

\subsection{Considerações sobre as Implementações}	

Boa parte dos programas desenvolvidos empregaram as RNAs com o seu aprendizado, executado por meio do algoritmo de retro-propagação. A escolha desse algoritmo deve-se à sua utilização no sistema KBANN, possibilitando a comparação de resultados. Os algoritmos que definiram as topologias de RNAs empregadas foram consequência da evolução natural das técnicas de programação.
Os valores de saída e as sinapses da RNA foram implementados por variáveis contidas nas classes Neurônio e Arestas. Quando se deseja acessar o valor contido em um neurônio específico, é utilizado uma estrutura de dados \emph{HashMap} que possui todos os objetos neurônios. Dentro de cada neurônio existe os campos que identifica se ele é da camada de entrada, saída ou de qual camada intermediária ele faz parte. 

\subsection{Testes do Sistema}

Para validação do sistema desenvolvido, foi utilizado o \emph{software} \emph{Matlab\textregistered} como referência, devido as suas diversas ferramentas amplamente testadas pela comunidade científica. Para realização do teste, foi necessário criar um exemplo de rede MLP de acordo com o que podia ser modelado no \emph{Matlab\textregistered}. Na Figura \ref{fig:RedeMatlabEstrutura}, a sua estrutura da rede MLP pode ser vista após a definição do problema. Esse teste objetivou apenas que os resultados encontrados no programa fossem relativamente parecidos ou próximos do que o \emph{Matlab} gerou. 

\begin{figure}[H] 
	\begin{center}
		\caption{Topologia da rede MLP no \emph{Matlab}}
		\includegraphics[scale=0.5]{imagens/RedeMatlabEstrutura.png}
		\label{fig:RedeMatlabEstrutura}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}

A Figura \ref{fig:RedeMatlabEstrutura}, representa a estrutura da rede a ser treinada. A rede possui 4 neurônios na sua camada de entrada ($input$), 2 neurônios em sua única camada oculta e uma única classe de representação na camada de saída ($output$). O problema apresentado a essa rede é de padrão lógico, ou seja, informações binárias e foram gerados 16 saídas para as 16 possíveis entradas. Os dados contidos nesse padrão para serem apresentados a rede, correspondem ao domínio completo, ou seja, como realmente funciona o sistema. Nesse teste foi considerado que a MLP não iria possuir em sua topologia todas as regras que definem o problema, sendo assim, foram retiradas 2 regras do domínio apresentado, o que de fato, se espera que gerasse alguns erros na rede ou até mesmo não convergir.

\begin{figure}[H] 
	\begin{center}
		\caption{Parâmetros após treinamento da Rede MLP no \emph{Matlab}}
		\includegraphics[scale=0.5]{imagens/RedeMatlabTreinada.png}
		\label{fig:RedeMatlabTreinada}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}

Pelo o que foi apresentado na Figura \ref{fig:RedeMatlabTreinada}, pode-se observar que o \emph{Neural Network ToolBox}  do \emph{Matlab\textregistered} levou 10.000 épocas para finalizar o problema, ou seja, o erro de treinamento ou o erro de validação aceitável não foi alcançado, sendo necessário utilizar a quantidade de épocas máxima para finalizar o treinamento. Nesse exemplo, foi utilizado o algoritmo de \emph{backpropagation} e a função de ativação dos neurônios escolhida foi a sigmóide. Outros parâmetros, como taxa de aprendizagem, erro aceitável ($goal$) e o tempo para simulação podem ser verificados na Figura \ref{fig:redeMatlabParametros}.

\begin{figure}[H] 
	\begin{center}
		\caption{Parâmetros da rede MLP treinada}
		\includegraphics[scale=0.5]{imagens/redeMatlabParametros.png}
		\label{fig:redeMatlabParametros}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}

As duas últimas Figuras (\ref{fig:GraficoErroMatlab} e \ref{fig:errosMatlab}) mostram a baixa capacidade de uma rede MLP em classificar dados sem possuir conhecimento prévio. Nesse caso, a estrutura da rede é idêntica a que foi aplicada no KBANN, mas os pesos iniciais foram gerados de forma aleatória. Dessa forma, o algoritmo \emph{backpropagation} irá tentar ajustar os pesos para que a rede consiga gerar respostas corretas. Para todas as 16 amostras apresentadas a rede, a mesma não obteve um resultado próximo a resposta desejada, em todas as saídas tiveram erros acima de 39\%, o que é um erro considerável.  Para um melhor entendimento sobre o resultado gerados na Figura \ref{fig:errosMatlab}, é comentado um dos resultados. A primeira saída gerada pela rede para a entrada (0, 0, 0, 0) foi 0.73587. Nesse caso, a resposta deseja é 0, ou seja, um erro aproximado de 73\% para essa entrada. O ajuste necessário a ser aplicado para corrigir esse erro é de -0.73587, conforme é apresentado na Figura \ref{fig:resultado1SemTopgen}. 

\begin{figure}[H] 
	\begin{center}
		\caption{Gráfico do erro de treinamento, validação e teste}
		\includegraphics[scale=0.5]{imagens/GraficoErroMatlab.png}
		\label{fig:GraficoErroMatlab}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}

\begin{figure}[H] 
	\begin{center}
		\caption{Resultados gerados na saída da rede}
		\includegraphics[scale=0.5]{imagens/errosMatlab.png}
		\label{fig:errosMatlab}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}

O mesmo teste considerando as mesmas configurações da rede (taxa de aprendizado, função de ativação) e o conjunto de dados foram realizados pelo sistema desenvolvido utilizando apenas o KBANN, e em seguida, o KBANN com o TopGen. Na Figura \ref{fig:resultado1SemTopgen} a rede KBANN conseguiu classificar corretamente todos os dados apresentados em sua saída (A), mas obteve dois erros em uma saída intermediária (B), em que obteve dois falsos negativos. Esses erros já eram esperados devido a retirada de duas regras do domínio que rege esse problema.

\begin{figure}[H] 
	\begin{center}
		\caption{Resultados gerados na saída da rede apenas com KBANN}
		\includegraphics[scale=0.5]{imagens/resultado1_semTopGen.png}
		\label{fig:resultado1SemTopgen}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}

Na Figura \ref{fig:resultado1ComTopgen}, pode-se observar que o erro em todas as saídas intermediárias (B e C), assim como a saída principal da rede (A) foram zeradas, ou seja, para todos os dados apresentados, foram classificados corretamente sem nenhuma exceção, mostrando assim, uma boa eficácia do sistema. Para se conseguir esse resultado, foram necessários adicionar a rede original de KBANN, dois neurônios, o TG1B e TG2B (Figura \ref{fig:resultado1RedeComTopgen}), o motivo dessa adição pode ser vista na seção (2.3). Esse neurônios fizeram com que os erros da saída intermediária (B) fossem zerados sem modificar o aprendizado obtido em outras regiões da rede.

\begin{figure}[H] 
	\begin{center}
		\caption{Resultados gerados na saída da rede com KBANN e TopGen}
		\includegraphics[scale=0.5]{imagens/resultado1_comTopGen.png}
		\label{fig:resultado1ComTopgen}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}

\begin{figure}[H] 
	\begin{center}
		\caption{Rede gerada com os novos neurônios a partir do TopGen}
		\includegraphics[scale=0.5]{imagens/resultado1_RedeComToGen.png}
		\label{fig:resultado1RedeComTopgen}
		\centerline{Fonte: Autor, 2017}
	\end{center} 
\end{figure}

Assim, após comprovar que o KBANN, juntamente com o TopGen, obtêm bons resultados quando aplicados em conjunto, foi possível realizar outros testes considerando um problema com uma quantidade maior de regras, e maior complexidade que serão apresentados no próximo capítulo.


