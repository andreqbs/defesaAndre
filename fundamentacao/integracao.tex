\label{Cap_2_3}

\section{Sistemas Híbridos}

O cérebro humano possui a notável capacidade de compreender, interpretar e produzir a linguagem humana. A Inteligência Artificial Conexionista se desenvolveu ao ponto de atingir algo parecido com o cérebro humano. As redes neurais artificiais e a lógica não possuem uma ligação tão próxima. Os mecanismos de inferência simbólicos e a aprendizagem estatística de máquina constituem dois dos principais paradigmas da inteligência artificial, mas são muito diferentes. Ambos possuem  pontos fortes e fracos: Os métodos estatísticos oferecem ferramentas flexíveis e altamente eficazes, ideais para dados possivelmente corrompidos ou ruidosos. Esses tipos de informações estão presentes na vida cotidiana, tais como: sensores em robótica, medições em medicina como EEG e EKG, índices de mercados financeiros, etc. 

Esses modelos, no entanto, são frequentemente reduzidos a mecanismos de caixa preta que complicam a integração de conhecimentos de nível superior ou entendimento humano. Modelos simbólicos, por outro lado, são perfeitamente intuitivos e facilmente aplicados para a interação homem-máquina. No entanto, sua capacidade de lidar com a incerteza, o ruído e com conjuntos de dados corrompidos de grande escala no mundo real é bastante limitada. Assim, as forças e fraquezas inerentes destes dois métodos complementam-se idealmente entre si.

Diversos pesquisadores desses dois paradigmas tentam combinar as forças das duas direções e ao mesmo tempo livrar-se de suas fraquezas eventualmente visando sistemas artificiais que poderiam ser competitivos às capacidades humanas de processamento de dados e inferência. Existem diferentes graus de integração neuro-simbólica: (1) Os pesquisadores incorporam aspectos de estruturas simbólicas em aprendizes estatísticos ou enriquecem o raciocínio estrutural por aspectos estatísticos para estender a aplicabilidade do respectivo paradigma. Como exemplo, os mecanismos de inferência lógica podem ser ampliados pelo raciocínio estatístico, baseando-se principalmente nas estatísticas \emph{bayesianas}. Os sistemas resultantes são capazes de resolver problemas complexos do mundo real, como demonstrado de forma impressionante nos recentes avanços da aprendizagem estatística-relacional. (2) Os pesquisadores tentam exatamente mapear os mecanismos de inferência de um paradigma para o outro, de modo que uma relação direta pode ser estabelecida e o paradigma que é idealmente adequado para a tarefa em questão pode ser escolhido sem quaisquer limitações no cenário. Esse trabalho se concentra na segunda forma de integração desses modelos.

\section{Knowledge-based Artificial Neural Networks (KBANN)}

Esta sub-seção descreve a metodologia KBANN, que a Figura 1 descreve como um par de algoritmos (nos arcos) que formam um sistema para aprender tanto da teoria quanto dos exemplos. O primeiro algoritmo, rotulado "Regras para Rede", está detalhado na Seção X.X. O algoritmo insere regras simbólicas aproximadamente corretas em uma rede neural. As redes criadas neste passo fazem as mesmas classificações que as regras em que se baseiam.
O segundo algoritmo do KBANN, denominado "\emph{Neural Learning}", refina as redes usando o algoritmo de aprendizagem \emph{backpropagation}. (Segundo o autor, apesar de todos testes usarem retropropagação, qualquer método aprendizado supervisionado - por exemplo, gradiente conjugado [Referencia] - funcionaria.) Embora o mecanismo de aprendizagem seja essencialmente uma retropropagação padrão, a rede que está sendo treinada não é padrão. Em vez disso, o primeiro algoritmo do KBANN constrói e inicializa a rede. Isso tem implicações para o treinamento. Ao concluir esta etapa, a rede treinada pode ser usada como um classificador muito preciso.

A próxima subseção apresenta uma breve visão geral do tipo de redes neurais que usamos. Subsequentemente, é uma visão geral de alto nível do KBANN. As duas subseções seguintes contêm descrições detalhadas de cada uma das etapas algorítmicas do KBANN.

\subsection{Inserção de Conhecimento em uma RNA}

O primeiro passo do KBANN é traduzir um conjunto de regras aproximadamente corretas em uma rede neural baseada no conhecimento. As regras a serem traduzidas em redes KBANN são expressas como cláusulas Horn. Existem duas restrições no conjunto de regras. Primeiro, as regras devem ser proposicionais. Esta restrição resulta do uso de algoritmos de aprendizado neural que, no momento, são incapazes de manipular variáveis de cálculo de predicado. Em segundo lugar, as regras devem ser acíclicas. Esta restrição "sem ciclos" simplifica o treinamento das redes resultantes. No entanto, ele não representa uma limitação fundamental no KBANN, pois existem algoritmos baseados em \emph{backpropagation} que podem ser usados para treinar redes com ciclos [Referencia]. Além disso, outros têm estendido KBANN para lidar gramáticas recursivas de estado finito [Refenrecia] \cite{bibid}.
Além dessas restrições, os conjuntos de regras fornecidos ao KBANN geralmente são hierarquicamente estruturados. Ou seja, as regras geralmente não mapeiam diretamente as entradas para as saídas. Em vez disso, pelo menos algumas das regras fornecem conclusões intermediárias que descrevem conjunções úteis dos recursos de entrada. Essas conclusões intermediárias podem ser utilizadas por outras regras para determinar a conclusão final ou outras conclusões intermediárias. É a estrutura hierárquica de um conjunto de regras que cria características derivadas para uso pelo sistema de aprendizagem baseado em exemplo. Assim, se o conhecimento de domínio não é hierarquicamente estruturado, então as redes criadas pelo KBANN não terão recursos que indicam dependências contextuais ou outras conjunções úteis dentro das descrições do exemplo. Além disso, a uma rede KBANN que resulta da tradução de um conjunto de regras sem conclusões intermediárias não teria unidades ocultas. Como resultado, seria capaz de utilizar apenas o \emph{Perceptron} como aprendizagem [Referencia]. A Tabela \ref{tab:tabelaKBANN}, mostra um resumo de como é mapeado a teoria de domínio em uma rede neural, por KBANN.

\begin{table}[h]
	\centering
	\caption{Correspondências entre bases de conhecimento e redes neurais.}
	\vspace{0.5cm}
	\label{tab:tabelaKBANN}
	\begin{tabular}{l|ll}
			\hline 
		Conhecimento base & $\Longleftrightarrow$  & Rede Neural \\ 
		\hline                               % para uma linha horizontal
		Conclusões finais &   $\Longleftrightarrow$    & Unidades de saída \\
		Suporte aos fatos & $\Longleftrightarrow$  & Unidades de entrada \\
		Conclusões intermediárias &   $\Longleftrightarrow $   & Unidades ocultas \\
		Dependências &   $\Longleftrightarrow$   & Conexões dos pesos
		
	\end{tabular}
\end{table}


\subsection{Algoritmo de Tradução de Regras}

A Tabela X é uma especificação abstrata do algoritmo de tradução de sete passos de regras para rede. Este algoritmo inicialmente traduz um conjunto de regras em uma rede neural. Em seguida, aumenta a rede de modo que ele é capaz de aprender conceitos não fornecidos pelas regras iniciais. Nesta subseção, é descrito, em detalhes, cada uma das sete etapas deste algoritmo.

\textbf{Reescrever}. A primeira etapa do algoritmo transforma o conjunto de regras em um formato que esclarece sua estrutura hierárquica e torna possível traduzir diretamente as regras em uma rede neural. Se houver mais de uma regra para um consequente, então cada regra para esse consequente com mais de um antecedente é re-escrita em duas regras. Uma dessas regras tem o consequente original e um único termo recém-criado como antecedente. A outra regra tem o termo recém-criado como seu consequente e os antecedentes da regra original como seus antecedentes. Por exemplo, a Figura X mostra a transformação de duas regras no formato requerido pelas próximas etapas do KBANN. (A necessidade dessa re-escrita é explicada em Referência).

\textbf{Mapeamento}. Na segunda etapa do algoritmo, o KBANN estabelece um mapeamento entre um conjunto transformado de regras e uma rede neural. Usando esse mapeamento, mostrado na Tabela X, o KBANN cria uma rede que têm uma correspondência um-para-um com elementos do conjunto de regras. Os pesos e os bias de todos as ligações especificadas pelo conjunto de regras das unidades correspondentes aos consequentes são definidos de modo que a rede responda exatamente da mesma maneira que o domínio inicial que foi passado.  Ao concluir esta etapa, a rede do KBANN tem as informações do conjunto de regras relativas as entradas relevantes e características derivadas. No entanto, não há nenhuma garantia de que o conjunto de regras se refere a todos os recursos relevantes ou fornece uma coleção significativa de recursos derivados. Assim, as quatro etapas seguintes aumentam a rede do KBANN com links adicionais, unidades de entrada e (possivelmente) unidades ocultas.

\textbf{Numeração}. Nesta etapa, KBANN numera as unidades nas redes KBANN por seu "nível". Esse número não é útil em si, mas é um precursor necessário para várias das etapas a seguir. O KBANN define o nível de cada unidade como sendo o comprimento do caminho mais longo para uma unidade de entrada.

\textbf{Adicionando unidades ocultas}. Esse passo adiciona unidades ocultas a rede KBANN, dando assim, a rede a capacidade de aprender características derivadas não especificadas no conjunto de regras inicial. A etapa é opcional, pois as regras iniciais geralmente fornecem um vocabulário suficiente para evitar a necessidade de adicionar unidades ocultas. Assim, as unidades ocultas são adicionadas somente a instruções específicas de um usuário. Esta instrução deve especificar o número e a distribuição entre os níveis estabelecidos na etapa anterior das unidades adicionadas. Essa etapa não foi implementada no trabalho devido a falta de clareza do autor em como proceder com a mesma.

\textbf{Adicionando unidades de entrada}. Nesta etapa, o KBANN aumenta sua rede com unidades de entrada não mencionados pelo conjunto de regras, mas que um especialista do domínio acredita serem relevantes. Essa adição é necessária porque um conjunto de regras que não é perfeitamente correto pode não identificar cada recurso de entrada necessário para aprender corretamente um conceito.

\textbf{Adicionando links}. No penúltimo passo, o algoritmo adiciona links com peso  zero na rede usando a numeração das unidades estabelecidas na etapa 4. Conexões são adicionados para conectar cada unidade de uma camada n a uma camada imediatamente seguinte, n + 1. 

\textbf{Perturbação}. O passo final na tradução de rede para regras é perturbar todos os pesos na rede adicionando um pequeno número aleatório a cada peso. Essa perturbação é muito pequena para ter um efeito nos cálculos da rede KBANN antes do treinamento. No entanto, é suficiente para evitar problemas causados pela simetria [Referencia].

\subsection{Exemplo do algoritmo}

A Figura \ref{fig:algoritmoKbann} mostra uma tradução passo-a-passo de um conjunto simples de regras para uma rede KBANN. O painel a mostra um conjunto de regras na notação PROLOG. O painel \emph{b} é o mesmo conjunto de regras depois de terem sido reescritos na etapa 1 do algoritmo de tradução. As únicas regras afetadas pela reescrita são duas que, juntas, formam uma definição disjuntiva do consequente B.

\begin{figure}[H] 
	\begin{center}
		\caption{Demonstração do algoritmo de KBANN.}
		\includegraphics[scale=0.5]{imagens/algoritmoKbann.png}
		\label{fig:algoritmoKbann}
		Fonte :
	\end{center} 
\end{figure}


O painel \emph{c} é uma representação gráfica das regras no painel \emph{b} que mostra a estrutura hierárquica das regras. Nessa figura, as linhas pontilhadas representam antecedentes negados, enquanto as linhas contínuas e sólidas representam antecedentes não negados. 
A próxima etapa do algoritmo de tradução (etapa 2 na Tabela X) é criar uma rede neural mapeando a estrutura hierárquica das regras em uma rede. Como resultado, há pouca diferença visual entre as representações da inicial rede KBANN no painel \emph{d} e a estrutura hierárquica das regras no painel \emph{c}.
Os painéis \emph{e} e \emph{f} ilustram o processo pelo qual as ligações, unidades de entrada e unidades ocultas não especificadas no conjunto de regras são adicionadas à rede. O painel \emph{e} mostra unidades na rede numeradas pelo seu "nível". Além disso, o painel \emph{e} mostra uma unidade oculta (sombreada) adicionada à rede no nível um. 
Painel \emph{f} mostra a rede depois de links com peso zero foram adicionados para conectar todas as unidades que estão separados por um nível. Observe que, além de fornecer às unidades existentes acesso a informações não especificadas pelo conhecimento do domínio, os links ponderados ligam as unidades ocultas adicionadas ao restante da rede.
Não há ilustração do passo final do algoritmo de tradução de regras para rede porque a perturbação dos pesos de ligação resulta apenas em alterações dos pesos.

%As correntes de pensamento que se cristalizaram em torno da IA já estavam em gestação desde os anos 30 [BF81]. No entanto, oficialmente, a IA nasceu em 1956 com uma conferência de verão em Dartmouth College, NH, USA. Na proposta dessa conferência, escrita por John McCarthy (Dartmouth), Marvin Minsky (Hardward), Nathaniel Rochester (IBM) e Claude Shannon (Bell Laboratories) e submetida à fundação Rockfeller, consta a intenção dos autores de realizar ?um estudo durante dois meses, por dez homens, sobre o tópico inteligência artificial''. Ao que tudo indica, esta parece ser a primeira menção oficial à expressão ?Inteligência Artificial'' [McC79]. Desde seus primórdios, a IA gerou polêmica, a começar pelo seu próprio nome, considerado presunçoso por alguns, até a definição de seus objetivos e metodologias. O desconhecimento dos princípios que fundamentam a inteligência, por um lado, e dos limites práticos da capacidade de processamento dos computadores, por outro, levou periodicamente a promessas exageradas e às correspondentes decepções.

%Existem duas linhas principais de pesquisa para a construção de sistemas inteligentes: a linha conexionista e a linha simbólica .

%Conexionista visa à modelagem da inteligência humana através da simulação dos componentes do cérebro, isto é, de seus neurônios, e de suas interligações. Esta proposta foi formalizada inicialmente em 1943, quando o neuropsicólogo McCulloch e o lógico Pitts propuseram um primeiro modelo matemático para um neurônio. Um primeiro modelo de rede neuronal , isto é, um conjunto de neurônios interligados, foi proposto por Rosenblatt. Este modelo, chamado Perceptron , teve suas limitações demonstradas por Minsky e Papert [MP69] em livro onde as propriedades matemáticas de redes artificiais de neurônios são analisadas. Durante um longo período essa linha de pesquisa não foi muito ativa, mas o advento dos microprocessadores, pequenos e baratos, tornou praticável a implementação de máquinas de conexão compostas de milhares de microprocessadores, o que, aliado à solução de alguns problemas teóricos importantes, deu um novo impulso às pesquisas na área. O modelo conexionista deu origem à área de redes neuronais artificiais.

%Simbólica segue a tradição lógica e teve em McCarthy e Newell seus principais defensores. Os princípios dessa linha de pesquisa são apresentados no artigo Physical symbol systems de Newell [New80]. O sucesso dos sistemas especialistas (SE) (do inglês, ?expert system''), a partir da década de setenta, estabeleceu a manipulação simbólica de um grande número de fatos especializados sobre um domínio restrito como o paradigma corrente para a construção de sistemas inteligentes do tipo simbólico. Para facilitar a apresentação, vamos dividir a história da IA simbólica em ?épocas'', conforme proposto em relatórios internos do MIT (Massachusetts Institute of Technology)

\section{Top-Gen}

O algoritmo doTopGen pesquisa heuristicamente as possíveis maneiras de adicionar um "nó" à rede, tentando encontrar a melhor topologia que refine a teoria do domínio inicial. Resumidamente, o TopGen procura "nós" na rede com altas taxas de erro e, em seguida, adiciona novos nós a essas partes da rede.
A Tabela 1 resume o algoritmo TopGen baseado em feixe-pesquisa. TopGen usa dois conjuntos de validação, um para avaliar as diferentes topologias de rede e um segundo para ajudar a decidir onde novos nós devem ser adicionados (o segundo conjunto de validação também é utilizado para decidir quando parar de treinar as novas redes encontradas). O TopGen usa o algoritmo de tradução de regra-para-rede do KBANN (discutido na seção anterior) para definir uma topologia inicial de rede neural. Essa rede é treinada usando \emph{backpropagation} (Rumelhart et al., 1986) e é colocada em uma lista, chamada de \emph{Open}. Em cada ciclo, o TopGen busca a melhor rede da lista \emph{Open} (conforme medido pelo segundo conjunto de validação), e decide as possíveis maneiras de adicionar novos "nós", em seguida treina essas novas redes e as coloca na lista \emph{Open}. Este processo é repetido até atingir um dos seguintes critérios: (a) uma precisão de 100\% em cima do segundo conjunto validação ou (b) um limite de épocas previamente estabelecido.

\subsection{Localização de novos Neurônios}

Primeiramente o algoritmo deve encontrar "nós" na rede com altas taxas de erros. Isso é feito marcando cada nó (que corresponde a uma regra em uma teoria do domínio simbólico) sando exemplos do primeiro conjunto de validação. Utilizando esse conjunto de validação, o TopGen adiciona nós com base onde a rede não conseguiu generalizar o resultado. O TopGen mantém dois contadores para cada nó da rede, um para falsos negativos e outro para falsos positivos. Esse contadores são modificados de acordo com a saída individual de cada neurônio e não apenas em relação a saída final da rede. Para uma melhor compreensão, um exemplo é considerado falso negativo se for incorretamente classificado como exemplo negativo, enquanto um falso positivo é um classificado incorretamente como um exemplo positivo. O TopGen incrementa os contadores de acordo com a quantidade de vezes que foi alterando o valor "booleano" de saída de um "nó" levando a um exemplo mal classificado a ser classificado corretamente. Ou seja, se um nó estiver ativo para um exemplo errado e alterar sua saída para ser inativo e assim classificando de maneira correta o exemplo apresentado, isso fará que o contador de falsos positivos do nó seja incrementado. O contador de falsos negativos de um nó é incrementado seguindo o mesmo raciocínio. As novas redes serão geradas para tentar diminuir ou até mesmo eliminar o problema de cada neurônio, sendo que esse novo nó poderá também ajudar na redução de falsos negativos e positivos dos demais neurônios. A próxima subseção detalha como os nós são adicionados com base no tipo de contador (isto é, um contador falso negativo ou falso positivo) e o tipo de nó (isto é, um \emph{AND} ou \emph{OR}).

\subsection{Como novos Neurônios são Adicionados}

Uma vez estimado onde se deve adicionar novos "nós", é necessário saber como adicionar esses "nós". TopGen faz a suposição de que ao treinar uma de suas redes, o significado de um "nó" não muda significativamente. Fazer esta suposição permite alterar a rede de uma forma semelhante ao de refinar regras simbólicas. (Towell \& Shavlik, 1993; Towell, 1992) mostrou que era válido fazer uma suposição semelhante sobre as redes de KBANN. A Figura \ref{fig:topGenNos} mostra as possíveis formas de como o TopGen adiciona "nós" a uma rede. Em uma base de regra simbólica que possui muitos falsos negativos, é possível diminui-los descartando antecedentes de regras existentes ou adicionando novas regras para a base de regra.

\begin{figure}[H] 
	\begin{center}
		\caption{Formas possíveis para adicionar novos neurônios. Arcos indicam conexões do tipo \emph{AND}}
		\includegraphics[scale=0.5]{imagens/topGenNos.png}
		\label{fig:topGenNos}
	\end{center} 
\end{figure}

 Como o KBANN é eficiente em remover antecedentes das regras existentes, o TopGen adiciona nós, destinados a diminuir falsos negativos, de uma forma que é análoga à adição de uma nova regra à base de regra. Se o nó existente for um "nó" do tipo \emph{OR}, o TopGen adicionará um novo nó como seu filho (consulte a Figura \ref{fig:topGenNos}a) e conectará totalmente esse novo "nó" com as unidades de entrada. Se o nó existente for um "nó" do tipo \emph{AND}, o TopGen cria um novo nó \emph{OR} que é o pai do nó \emph{AND} original e outro novo "nó" que é conectado totalmente às entradas (Figura \ref{fig:topGenNos}c); TopGen move as conexões de saída do nó original (A na Figura \ref{fig:topGenNos}c) para se tornar as conexões de saída do novo "nó" \emph{OR}. Em uma base de regra simbólica, podemos diminuir falsos positivos adicionando antecedentes a regras existentes ou removendo regras da base de regra. Enquanto KBANN pode efetivamente remover regras (Towell, 1992), é menos eficaz adicionar antecedentes a regras e é incapaz de acrescentar (por indução) novos antecedentes. As Figuras \ref{fig:topGenNos}b e \ref{fig:topGenNos}d mostram os modos (analogamente às Figuras \ref{fig:topGenNos}a e \ref{fig:topGenNos}c explicadas acima) de adicionar antecedentes. Ao permitir essas adições, TopGen é capaz de adicionar regras cujos consequentes não foram previamente definidos na base de regra. TopGen manipula "nós" que não são \emph{AND} nem \emph{OR}, decidindo se esse "nó" está mais próximo de um nó \emph{AND} ou de um nó \emph{OR} (observando o bias do nó e os pesos de entrada).

Depois que os novos "nós" são adicionados, TopGen realiza o treinamento da rede pelo algoritmo do \emph{backpropagation}. Embora é desejado que os novos pesos representem a maior parte do erro, também queremos que os pesos antigos sejam alterados, se necessário. Ou seja, é necessário que os pesos antigos retenham o que aprenderam anteriormente, enquanto ao mesmo tempo se movem de acordo com a mudança de erro causada pela adição do novo "nó". Para resolver este problema, TopGen multiplica as taxas de aprendizagem de pesos existentes por uma quantidade constante (<= 1) cada vez que novos "nós" são adicionados, produzindo um declínio exponencial das taxas de aprendizagem. Não é desejável mudar a teoria do domínio, a menos que haja considerável evidência de que ela está incorreta. Ou seja, há um termo entre a mudança da teoria do domínio e desconsiderando os exemplos de treinamento não classificados com ruído. Para ajudar a resolver isso, TopGen usa um regulador de decaimento do peso (Hinton, 1986). Pesos que fazem parte do domínio original da teoria, tem uma decadência em direção ao seu valor inicial, enquanto outros pesos decaem em direção a zero. O termo de decaimento foi proposto por Rumelhart em 1987 (Weigand et al., 1990). A ideia do decréscimo de peso é adicionar, à função de custo usual, um termo que mede a distância de cada peso de seu valor inicial:

\begin{align}
Custo = \sum_{k \in T}{(SaídaDesejada_k - SaídaRede_k)}^2 + \lambda \sum_{i \in C} \frac{{(w_i - w_{inicial})}^2}{1 + {(w_i - w_{inicial})}^2}
\end{align}

O primeiro termo soma todos os exemplos de treino \emph{T}, enquanto o segundo termo soma todas as conexões \emph{C} . O regulador entre o desempenho ea distância dos valores iniciais é ponderado por $\lambda$.

\subsection{Exemplo do TopGen}

Suponha que a teoria do domínio da Figura \ref{fig:topGenEx} também deveria incluir a seguinte regra:
%$B: -: \no F, G, H$.
Embora se tenha treinado a rede KBANN mostrada na Figura \ref{fig:topGenNos}c com todos os exemplos possíveis, foi incapaz de aprender o conceito correto.

\begin{figure}[H] 
	\begin{center}
		\caption{Tradução das regras em uma rede KBANN}
		\includegraphics[scale=0.5]{imagens/topGenExemplo.png}
		\label{fig:topGenEx}
	\end{center} 
\end{figure}

TopGen começa treinando a rede na \ref{fig:topGenNos}c, obtendo nenhuma melhora na base de regra original. Em seguida, prossegue tomando exemplos mal classificados do conjunto de validação-1 para encontrar lugares onde pode ser benéfico adicionar "nós". O exemplo a seguir da categoria A é classificado incorretamente pela teoria de domínio:
%$\no F G  H \no I \no J \no  K L M$.
Enquanto o "nó" \emph{C} (da Figura \ref{fig:topGenNos}c está corretamente falso nesse exemplo, o "nó" \emph{B} é incorretamente falso, \emph{B} é falso, uma vez que \emph{B1} e \emph{B2} são falsos. Se \emph{B} tivesse sido verdadeiro, este exemplo teria sido classificado corretamente (já que \emph{C} é correto ), Então TopGen incrementa o contador corrigível-falso-negativo para B. TopGen também incrementa os contadores de \emph{B1}, \emph{B2} e \emph{A}, usando argumentos semelhantes.
Os "nós" \emph{B1}, \emph{B2}, \emph{B} e \emph{A} terão todos os contadores de correção-falso-negativo com alta taxas de erro após todos os exemplos serem processados. Dadas essas contagens elevadas, o TopGen considera a adição de "nós" \emph{OR} aos nós \emph{A}, \emph{B1} e \emph{B2}, como feito na Figura \ref{fig:topGenNos}, e também considera a adição de outra disjunção, análogo à Figura \ref{fig:topGenNos}a, ao "nó" B. Qualquer um destes para correções permite que a rede aprenda o conceito desejado. Como o TopGen prefere os nós mais distantes do nó de saída, então será adicionado em \emph{B1} ou \emph{B2}.


%%\subsection{Sensores tolerantes a falhas} 
%
%%\begin{figure}[H]
%%\begin{center}
%%\includegraphics[scale=0.95]{imagens/etapasdiagn.png}
%%\end{center}
%%\caption{Etapas diagnóstico de falhas.}
%%\label{Fig:etapasdiagn}
%%\end{figure}
