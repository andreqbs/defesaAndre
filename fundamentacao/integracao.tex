\label{Cap_2_3}

\section{Sistemas Híbridos}

O cérebro humano possui a notável capacidade de compreender, interpretar e produzir a linguagem humana. A inteligência artificial conexionista se desenvolveu ao ponto de atingir algo parecido com o cérebro humano. As redes neurais artificiais e a lógica não possuem uma ligação tão próxima. Os mecanismos de inferência simbólicos e a aprendizagem estatística de máquina constituem dois dos principais paradigmas da inteligência artificial, mas são muito diferentes. Ambos possuem pontos fortes e fracos: Os métodos estatísticos oferecem ferramentas flexíveis e altamente eficazes, ideais para dados possivelmente corrompidos ou ruidosos. Esses tipos de informações estão presentes na vida cotidiana, tais como: sensores em robótica, eletrocardiogramas na medicina, índices de mercados financeiros, etc. 

Esses modelos, no entanto, são frequentemente reduzidos a mecanismos de caixa preta que dificultam a integração de conhecimentos de nível superior ou entendimento humano. Modelos simbólicos, por outro lado, são perfeitamente intuitivos e facilmente aplicados para a interação homem-máquina. No entanto, sua capacidade de lidar com a incerteza, o ruído e com conjuntos de dados corrompidos de grande escala no mundo real é bastante limitada. Assim, as forças e fragilidades inerentes desses dois métodos complementam-se idealmente entre si.

Diversos pesquisadores desses dois paradigmas tentam combinar as forças das duas direções e ao mesmo tempo livrar-se de suas fragilidades eventualmente, visando sistemas artificiais que poderiam ser competitivos às capacidades humanas de processamento de dados e inferência. 

\subsection{Knowledge-based Artificial Neural Networks (KBANN)}

Esta subseção descreve a metodologia KBANN, que pode ser descrito como um sistema capaz de aprender a partir da teoria de domínio quanto por exemplos. O primeiro algoritmo, rotulado $Regras para Rede$, está detalhado na Seção 2.4.1 o algoritmo insere regras simbólicas em uma rede neural. A rede gerada nesse passo realiza a mesma classificação que as regras em que lhe deram origem.
O segundo algoritmo do KBANN, denominado \emph{Neural Learning}, refina as redes utilizando o algoritmo de aprendizagem \emph{backpropagation}. Segundo Towell \textit{et al.}, (1990), apesar de todos testes utilizarem retro-propagação, qualquer método aprendizado supervisionado funcionaria.) Embora o mecanismo de aprendizagem seja essencialmente uma retro-propagação padrão, a rede que está sendo treinada não segue o padrão de uma rede MLP com pesos aleatórios. Em vez disso, o primeiro algoritmo do KBANN constrói e inicializa a rede. Isso tem implicações diretas para o treinamento. Ao concluir esta etapa, a rede treinada pode ser utilizada como um classificador muito preciso. A próxima subseção apresenta como o conhecimento prévio é inserido na RNA.

\subsubsection{Inserção de Conhecimento em uma RNA}

O primeiro passo do KBANN é traduzir um conjunto de regras aproximadamente corretas em uma rede neural baseada no conhecimento. As regras a serem traduzidas em redes KBANN são expressas através de cláusulas Horn. Existem duas restrições no conjunto de regras. Primeiro, as regras devem ser proposicionais. Essa restrição resulta do uso de algoritmos de aprendizado neural que, no momento, são incapazes de manipular variáveis de cálculo de predicado. Em segundo lugar, as regras devem ser acíclicas. Essa restrição sem ciclos simplifica o treinamento das redes resultantes. No entanto, ele não representa uma limitação fundamental no KBANN, pois existem algoritmos baseados em \emph{backpropagation} que podem ser utilizados para treinar redes com ciclos (Towell \textit{et al.}, 1990).
Além dessas restrições, os conjuntos de regras fornecidos ao KBANN são hierarquicamente estruturados. Ou seja, as regras geralmente não mapeiam diretamente as entradas para as saídas. Em vez disso, pelo menos algumas das regras fornecem conclusões intermediárias que descrevem conjunções úteis dos recursos de entrada. Essas conclusões intermediárias podem ser utilizadas por outras regras para determinar a conclusão final ou outras conclusões intermediárias. É a estrutura hierárquica de um conjunto de regras que cria características derivadas para uso pelo sistema de aprendizagem baseado em exemplo. Assim, se o conhecimento de domínio não é hierarquicamente estruturado, então as redes criadas pelo KBANN não terão recursos que indicam dependências contextuais ou outras conjunções úteis dentro das descrições do exemplo. Além disso, a uma rede KBANN que resulta da tradução de um conjunto de regras sem conclusões intermediárias não teria unidades ocultas. Como resultado, seria capaz de utilizar apenas o \emph{Perceptron} como aprendizagem. A Tabela \ref{tab:tabelaKBANN}, mostra um resumo de como é mapeado a teoria de domínio em uma rede neural de KBANN.

\begin{table}[h]
	\centering
	\caption{Correspondências entre bases de conhecimento e redes neurais.}
	\vspace{0.5cm}
	\label{tab:tabelaKBANN}
	\begin{tabular}{l|ll}
			\hline 
		Conhecimento base & $\Longleftrightarrow$  & Rede Neural \\ 
		\hline                               % para uma linha horizontal
		Conclusões finais &   $\Longleftrightarrow$    & Unidades de saída \\
		Suporte aos fatos & $\Longleftrightarrow$  & Unidades de entrada \\
		Conclusões intermediárias &   $\Longleftrightarrow $   & Unidades ocultas \\
		Dependências &   $\Longleftrightarrow$   & Conexões dos pesos
		
	\end{tabular}
\end{table}


\subsubsection{Algoritmo de Tradução de Regras}

Nessa subseção, é descrito, em detalhes, cada uma das sete etapas desse algoritmo. 

\textbf{Reescrever} - A primeira etapa do algoritmo transforma o conjunto de regras em um formato que esclarece sua estrutura hierárquica, e torna possível traduzir diretamente as regras em uma rede neural. Se houver mais de uma regra para um consequente, então cada regra para esse consequente com mais de um antecedente é re-escrita em duas regras. Uma dessas regras tem o consequente original e um único termo recém-criado como antecedente. A outra regra tem o termo recém-criado como seu consequente e os antecedentes da regra original como seus antecedentes. Por exemplo, a Figura \ref{fig:reescrita} mostra a transformação de duas regras no formato requerido pelas próximas etapas do KBANN. O trabalho de (Towell \textit{et al.}, 1990) explica a necessidade de se aplicar essa reescrita.

\begin{figure}[H] 
	\begin{center}
		\caption{Eliminação de disjunções com mais de um antecedente.}
		\includegraphics[scale=0.5]{imagens/reescrita.png}
		\label{fig:reescrita}
		\centerline{Fonte: Towell, 1990}
	\end{center} 
\end{figure}


\textbf{Mapeamento} - Na segunda etapa do algoritmo, o KBANN estabelece um mapeamento entre um conjunto transformado de regras e uma rede neural. Usando esse mapeamento, mostrado na Tabela \ref{tab:tabelaKBANN}, o KBANN cria uma rede que têm uma correspondência um para um com elementos do conjunto de regras. Os pesos e os bias de todas as ligações especificadas pelo conjunto de regras das unidades correspondentes aos consequentes são definidos de modo que a rede responda exatamente da mesma maneira que o domínio inicial que foi passado. Ao concluir essa etapa, a rede do KBANN tem as informações do conjunto de regras relativas as entradas relevantes e características derivadas. No entanto, não há nenhuma garantia de que o conjunto de regras se refere a todos os recursos relevantes ou fornece uma coleção significativa de recursos derivados. Assim, as quatro etapas seguintes aumentam a rede do KBANN com links adicionais, unidades de entrada e (possivelmente) unidades ocultas.

\textbf{Numeração}-  Nessa etapa, KBANN enumera as unidades nas redes KBANN por nível. Esse número influência diretamente nas etapas seguintes. O KBANN define o nível de cada unidade como sendo o comprimento do caminho mais longo para a unidade de saída.

\textbf{Adicionando unidades ocultas} - Esse passo adiciona unidades ocultas a rede KBANN, dando assim, a rede a capacidade de aprender características derivadas não especificadas no conjunto de regras inicial. A etapa é opcional, pois as regras iniciais geralmente fornecem um vocabulário suficiente para evitar a necessidade de adicionar unidades ocultas. Assim, as unidades ocultas são adicionadas somente a instruções específicas de um usuário. Essa instrução deve especificar o número e a distribuição entre os níveis estabelecidos na etapa anterior das unidades adicionadas. Essa etapa não foi implementada no trabalho devido a falta de clareza do autor em como proceder com a mesma.

\textbf{Adicionando unidades de entrada} - Nessa etapa, o KBANN aumenta sua rede com unidades de entrada não mencionados pelo conjunto de regras, mas que um especialista do domínio acredita serem relevantes. Essa adição é necessária porque um conjunto de regras que não é perfeitamente correto pode não identificar cada recurso de entrada necessário para aprender corretamente um conceito.

\textbf{Adicionando links} - No penúltimo passo, o algoritmo adiciona links com peso próximo a zero na rede utilizando a numeração das unidades estabelecidas na etapa 4. Conexões são adicionados para conectar cada unidade de uma camada $n$ a uma camada imediatamente seguinte, $n + 1$. 

\textbf{Perturbação}. O passo final na tradução de rede para regras é perturbar todos os pesos na rede adicionando um pequeno número aleatório a cada peso. Essa perturbação é muito pequena para ter um efeito nos cálculos da rede KBANN antes do treinamento. No entanto, é suficiente para evitar problemas causados pela simetria.

\subsubsection{Exemplo do algoritmo}

A Figura \ref{fig:algoritmoKbann} mostra uma tradução passo a passo de um conjunto simples de regras para uma rede KBANN. O painel $a$ mostra um conjunto de regras na notação Prolog. O painel \emph{b} é o mesmo conjunto de regras depois de terem sido re-escritos na etapa 1 do algoritmo de tradução. As únicas regras afetadas pela reescrita são duas que, juntas, formam uma definição disjuntiva do consequente $B$.

\begin{figure}[H] 
	\begin{center}
		\caption{Demonstração do algoritmo de KBANN.}
		\includegraphics[scale=0.5]{imagens/algoritmoKbann.png}
		\label{fig:algoritmoKbann}
		\centerline{Fonte: Towell, 1990}
	\end{center} 
\end{figure}


O painel \emph{c} é uma representação gráfica das regras no painel \emph{b} que mostra a estrutura hierárquica das regras. Na Figura \ref{fig:algoritmoKbann}, as linhas pontilhadas representam antecedentes negados, enquanto as linhas contínuas e sólidas representam antecedentes não negados. 

A próxima etapa do algoritmo de tradução é criar uma rede neural mapeando a estrutura hierárquica das regras. Como resultado, há pouca diferença visual entre as representações da inicial rede KBANN no painel \emph{d} e a estrutura hierárquica das regras no painel \emph{c}.
Os painéis \emph{e} e \emph{f} ilustram o processo pelo qual as ligações, unidades de entrada e unidades ocultas não especificadas no conjunto de regras são adicionadas à rede. O painel \emph{e} mostra unidades na rede numeradas pelo seu nível. Além disso, o painel \emph{e} mostra uma unidade oculta (sombreada) adicionada à rede no nível 1 (um). 
O painel \emph{f} mostra a rede depois de links com peso zero foram adicionados para conectar todas as unidades que estão separados por um nível. Observe que, além de fornecer às unidades existentes acesso a informações não especificadas pelo conhecimento do domínio, os \emph{links} ponderados ligam as unidades ocultas adicionadas ao restante da rede.
Não há ilustração do passo final do algoritmo de tradução de regras para rede porque a perturbação dos pesos de ligação resulta apenas em alterações dos pesos.

%As correntes de pensamento que se cristalizaram em torno da IA já estavam em gestação desde os anos 30 [BF81]. No entanto, oficialmente, a IA nasceu em 1956 com uma conferência de verão em Dartmouth College, NH, USA. Na proposta dessa conferência, escrita por John McCarthy (Dartmouth), Marvin Minsky (Hardward), Nathaniel Rochester (IBM) e Claude Shannon (Bell Laboratories) e submetida à fundação Rockfeller, consta a intenção dos autores de realizar ?um estudo durante dois meses, por dez homens, sobre o tópico inteligência artificial''. Ao que tudo indica, esta parece ser a primeira menção oficial à expressão ?Inteligência Artificial'' [McC79]. Desde seus primórdios, a IA gerou polêmica, a começar pelo seu próprio nome, considerado presunçoso por alguns, até a definição de seus objetivos e metodologias. O desconhecimento dos princípios que fundamentam a inteligência, por um lado, e dos limites práticos da capacidade de processamento dos computadores, por outro, levou periodicamente a promessas exageradas e às correspondentes decepções.

%Existem duas linhas principais de pesquisa para a construção de sistemas inteligentes: a linha conexionista e a linha simbólica .

%Conexionista visa à modelagem da inteligência humana através da simulação dos componentes do cérebro, isto é, de seus neurônios, e de suas interligações. Esta proposta foi formalizada inicialmente em 1943, quando o neuropsicólogo McCulloch e o lógico Pitts propuseram um primeiro modelo matemático para um neurônio. Um primeiro modelo de rede neuronal , isto é, um conjunto de neurônios interligados, foi proposto por Rosenblatt. Este modelo, chamado Perceptron , teve suas limitações demonstradas por Minsky e Papert [MP69] em livro onde as propriedades matemáticas de redes artificiais de neurônios são analisadas. Durante um longo período essa linha de pesquisa não foi muito ativa, mas o advento dos microprocessadores, pequenos e baratos, tornou praticável a implementação de máquinas de conexão compostas de milhares de microprocessadores, o que, aliado à solução de alguns problemas teóricos importantes, deu um novo impulso às pesquisas na área. O modelo conexionista deu origem à área de redes neuronais artificiais.

%Simbólica segue a tradição lógica e teve em McCarthy e Newell seus principais defensores. Os princípios dessa linha de pesquisa são apresentados no artigo Physical symbol systems de Newell [New80]. O sucesso dos sistemas especialistas (SE) (do inglês, ?expert system''), a partir da década de setenta, estabeleceu a manipulação simbólica de um grande número de fatos especializados sobre um domínio restrito como o paradigma corrente para a construção de sistemas inteligentes do tipo simbólico. Para facilitar a apresentação, vamos dividir a história da IA simbólica em ?épocas'', conforme proposto em relatórios internos do MIT (Massachusetts Institute of Technology)

\subsection{Top-Gen}

O algoritmo do TopGen pesquisa heuristicamente as possíveis maneiras de adicionar um neurônio à rede, tentando encontrar a melhor topologia que refine a teoria do domínio inicial. Resumidamente, o TopGen procura neurônios na rede com altas taxas de erro e, em seguida, adiciona novos neurônios a essas partes da rede.
A Figura \ref{fig:AlgoritmoTopGen} resume o algoritmo TopGen. O algoritmo utiliza dois conjuntos de validação, um para avaliar as diferentes topologias de rede e, um segundo para ajudar a decidir onde novos neurônios devem ser adicionados (o segundo conjunto de validação também é utilizado para decidir quando parar de treinar as novas redes encontradas). O TopGen utiliza o algoritmo de tradução de regra-para-rede do KBANN (discutido na seção anterior) para definir uma topologia inicial de rede neural. Essa rede é treinada utilizando \emph{backpropagation} e é colocada em uma lista, chamada de \emph{Open}. Em cada ciclo, o TopGen busca a melhor rede da lista \emph{Open} (conforme medido pelo segundo conjunto de validação), e decide as possíveis maneiras de adicionar novos neurônios, em seguida treina essas novas redes e as coloca na lista \emph{Open}. Esse processo é repetido até atingir um dos seguintes critérios: (a) uma precisão de 100\% em relação ao segundo conjunto de validação ou (b) um limite de épocas previamente estabelecido.

\subsubsection{Localização de Novos Neurônios}

Primeiramente o algoritmo (Figura \ref{fig:AlgoritmoTopGen}) deve encontrar neurônios na rede com altas taxas de erros. Isso é feito marcando cada neurônio (que corresponde a uma regra em uma teoria do domínio simbólico) sendo exemplos do primeiro conjunto de validação. Utilizando esse conjunto de validação, o TopGen adiciona neurônios com base onde a rede não conseguiu generalizar o resultado. O TopGen mantém dois contadores para cada neurônio da rede, um para falsos negativos e outro para falsos positivos. Esse contadores são modificados de acordo com a saída individual de cada neurônio e não apenas em relação a saída final da rede. Para uma melhor compreensão, um exemplo é considerado falso negativo se for incorretamente classificado como exemplo negativo, enquanto um falso positivo é um classificado incorretamente como um exemplo positivo. O TopGen incrementa os contadores de acordo com a quantidade de vezes que foi alterando o valor lógico de saída de um neurônio, levando a um exemplo mal classificado a ser classificado corretamente. Ou seja, se um neurônio estiver ativo para um exemplo errado, e alterar sua saída para ser inativo, e assim classificando de maneira correta o exemplo apresentado, isso fará que o contador de falsos positivos do neurônio seja incrementado. O contador de falsos negativos de um neurônio é incrementado seguindo o mesmo raciocínio. As novas redes serão geradas para tentar diminuir ou até mesmo eliminar o problema de cada neurônio, sendo que esse novo neurônio poderá também ajudar na redução de falsos negativos e positivos dos demais neurônios. A próxima subseção detalha como os neurônios são adicionados com base no tipo de contador (isto é, um contador falso negativo ou falso positivo) e o tipo de neurônio (isto é, um \emph{AND} ou \emph{OR}).

\begin{figure}[H] 
	\begin{center}
		\caption{Algoritmo TopGen}
		\includegraphics[scale=0.5]{imagens/AlgoritmoTopGen.png}
		\label{fig:AlgoritmoTopGen}
		\centerline{Fonte: Shavlik, 1995}
	\end{center} 
\end{figure}

\subsubsection{Como Novos Neurônios são Adicionados}

Uma vez estimado onde se deve adicionar novos neurônios, é necessário saber como adicionar esses neurônios. TopGen faz a suposição de que, ao treinar uma de suas redes, o significado de um neurônio não mude significativamente. Fazer essa suposição permite alterar a rede de uma forma semelhante ao de refinar regras simbólicas. (Towell \textit{et al.}, 1990) mostrou que era válido fazer uma suposição semelhante sobre as redes de KBANN. A Figura \ref{fig:topGenNos} mostra as possíveis formas de como o TopGen adiciona neurônios a uma rede. Em uma base de regra simbólica que possui muitos falsos negativos, é possível diminuí-los descartando antecedentes de regras existentes ou adicionando novas regras para a base original.

\begin{figure}[H] 
	\begin{center}
		\caption{Formas possíveis para adicionar novos neurônios. Arcos indicam conexões do tipo \emph{AND}}
		\includegraphics[scale=0.5]{imagens/topGenNos.png}
		\label{fig:topGenNos}
	\centerline{Fonte: Shavlik, 1995}
	\end{center} 
\end{figure}

 Como o KBANN é eficiente quando se remove antecedentes das regras existentes, o TopGen adiciona neurônios, destinados a diminuir falsos negativos, de uma forma que é análoga à adição de uma nova regra à base de regras. Se o neurônio existente for um neurônio do tipo \emph{OR}, o TopGen adicionará um novo neurônio como seu filho (Figura \ref{fig:topGenNos}a) e conectará totalmente esse novo neurônio com as unidades de entrada. Se o neurônio existente for um neurônio do tipo \emph{AND}, o TopGen cria um novo neurônio \emph{OR} que é o pai do neurônio \emph{AND} original e outro novo neurônio que é conectado totalmente às entradas (Figura \ref{fig:topGenNos}c); O TopGen move as conexões de saída do neurônio original (Figura \ref{fig:topGenNos}c) para se tornar as conexões de saída do novo neurônio \emph{OR}. Em uma base de regras simbólica, pode-se diminuir falsos positivos adicionando antecedentes a regras existentes ou removendo regras da base de regra. Enquanto KBANN pode efetivamente remover regras (Towell, 1992), é menos eficaz adicionar antecedentes a regras e é incapaz de acrescentar (por indução) novos antecedentes. As Figuras \ref{fig:topGenNos}b e \ref{fig:topGenNos}d mostram os modos (analogamente às Figuras \ref{fig:topGenNos}a e \ref{fig:topGenNos}c explicadas acima) de adicionar antecedentes. Ao permitir essas adições, o TopGen é capaz de adicionar regras cujos consequentes não foram previamente definidos na base de regra. O TopGen manipula neurônios que não são \emph{AND} nem \emph{OR}, decidindo se esse neurônio está mais próximo de um neurônio \emph{AND} ou de um neurônio \emph{OR} (observando o bias do neurônio e os pesos de entrada).

Depois que os novos neurônios são adicionados, o TopGen realiza o treinamento da rede pelo algoritmo do \emph{backpropagation}. Embora é desejado que os novos pesos representem a maior parte do erro, também se espera que os pesos antigos sejam alterados, se necessário. Ou seja, é necessário que os pesos antigos retenham o que aprenderam anteriormente, enquanto ao mesmo tempo se movem de acordo com a mudança de erro causada pela adição do novo neurônio. Para resolver esse problema, o TopGen multiplica as taxas de aprendizagem de pesos existentes por uma quantidade constante ($<= 1$) cada vez que novos neurônios são adicionados, produzindo um declínio exponencial das taxas de aprendizagem. Não é desejável mudar a teoria do domínio, a menos que haja considerável evidência de que ela está incorreta. Ou seja, há um termo entre a mudança da teoria do domínio e desconsiderando os exemplos de treinamento não classificados com ruído. Para ajudar a resolver isso, o TopGen utiliza um regulador de decaimento do peso (Hinton, 1986). Pesos que fazem parte do domínio original da teoria, tem uma decadência em direção ao seu valor inicial, enquanto outros pesos decaem em direção a zero. O termo de decaimento foi proposto por Rumelhart em 1987 (Weigand \textit{et al.}, 1990). A ideia do decréscimo de peso é adicionar, à função de custo usual, um termo que mede a distância de cada peso de seu valor inicial:

\begin{align}
Custo = \sum_{k \in T}{(SaidaAlvo_k - SaidaRede_k)}^2 + \lambda \sum_{i \in C} \frac{{(w_i - w_{inicial})}^2}{1 + {(w_i - w_{inicial})}^2}
\end{align}

O primeiro termo da equação 2.15 soma todos os exemplos de treino \emph{T}, enquanto o segundo termo soma todas as conexões \emph{C}. O regulador entre o desempenho ea distância dos valores iniciais é ponderado por $\lambda$.

\subsubsection{Exemplo do TopGen}

Suponha que a teoria do domínio da Figura \ref{fig:topGenEx} também deveria incluir a seguinte regra:
%$B: -: \no F, G, H$.
Embora se tenha treinado a rede KBANN mostrada na Figura \ref{fig:topGenNos}c com todos os exemplos possíveis, foi incapaz de aprender o conceito correto.

\begin{figure}[H] 
	\begin{center}
		\caption{Tradução das regras em uma rede KBANN}
		\includegraphics[scale=0.5]{imagens/topGenExemplo.png}
		\label{fig:topGenEx}
		\centerline{Fonte: Shavlik, 1995}
	\end{center} 
\end{figure}

O TopGen começa treinando a rede na \ref{fig:topGenEx}c, obtendo nenhuma melhora na base de regra original. Em seguida, prossegue tomando exemplos mal classificados do conjunto de validação-1 para encontrar lugares onde pode ser benéfico adicionar neurônios. O exemplo a seguir da categoria A é classificado incorretamente pela teoria de domínio:
\newline \newline
\centerline{$not D \wedge E \wedge F \wedge  G \wedge not H \wedge not I \wedge J \wedge K$}
\newline \newline
Enquanto o neurônio \emph{C} (da Figura \ref{fig:topGenEx}c está corretamente falso nesse exemplo, o neurônio \emph{B} é incorretamente falso, \emph{B} é falso, uma vez que \emph{B1} e \emph{B2} são falsos. Se \emph{B} tivesse sido verdadeiro, esse exemplo teria sido classificado corretamente (já que \emph{C} é correto), então TopGen incrementa o contador corrigível-falso-negativo para B. O TopGen também incrementa os contadores de \emph{B1}, \emph{B2} e \emph{A}, utilizando argumentos semelhantes.
Os neurônios \emph{B1}, \emph{B2}, \emph{B} e \emph{A} terão todos os contadores de correção-falso-negativo com alta taxas de erro após todos os exemplos serem processados. Dadas essas contagens elevadas, o TopGen considera a adição de neurônios \emph{OR} aos neurônios \emph{A}, \emph{B1} e \emph{B2}, como feito na Figura \ref{fig:topGenEx}, e também considera a adição de outra disjunção, análogo à Figura \ref{fig:topGenEx}a, ao neurônio B. Qualquer um desses para correções permite que a rede aprenda o conceito desejado. Como o TopGen prefere os neurônios mais distantes do neurônio de saída, então será adicionado em \emph{B1} ou \emph{B2}.


%%\subsection{Sensores tolerantes a falhas} 
%
%%\begin{figure}[H]
%%\begin{center}
%%\includegraphics[scale=0.95]{imagens/etapasdiagn.png}
%%\end{center}
%%\caption{Etapas diagnóstico de falhas.}
%%\label{Fig:etapasdiagn}
%%\end{figure}
