\label{Cap_2_3}

\section{Sistemas Híbridos}

O cérebro humano possui a notável capacidade de compreender, interpretar e produzir a linguagem humana. A inteligência artificial conexionista se desenvolveu ao ponto de atingir algo parecido com a inteligência humana. As redes neurais artificiais e a lógica não possuem uma ligação tão próxima. Os mecanismos de inferência simbólicos e a aprendizagem estatística de máquina constituem dois dos principais paradigmas da inteligência artificial, embora sejam muito diferentes. Ambos possuem pontos fortes e fracos: Os métodos estatísticos oferecem ferramentas flexíveis e altamente eficazes, ideais para dados possivelmente corrompidos. 

Esses modelos, no entanto, são frequentemente reduzidos a mecanismos de caixa preta que dificultam a integração de conhecimentos de nível superior ou entendimento humano. Os modelos simbólicos, por outro lado, são perfeitamente intuitivos e facilmente aplicados para a interação homem-máquina. No entanto, sua capacidade de lidar com a incerteza, o ruído e com conjuntos de dados corrompidos é bastante limitada. Assim, as forças e fragilidades inerentes desses dois métodos complementam-se idealmente entre si.

Diversos pesquisadores desses dois paradigmas como, Misnky (1991), Kurfess (1997), Russell (1996) e Mitchell (1997) tentaram combinar as forças das duas direções e ao mesmo tempo livrar-se de suas fragilidades eventualmente, visando sistemas artificiais que poderiam ser competitivos às capacidades humanas de processamento de dados e inferência. 

\subsection{Knowledge-based Artificial Neural Networks (KBANN)}

Esta subseção descreve a metodologia KBANN, que pode ser descrito como um sistema capaz de aprender a partir da teoria de domínio quanto por exemplos. O primeiro algoritmo, rotulado Regras para Rede, é detalhado na Seção 2.4.1 e tem como função a inserção de regras simbólicas em uma rede neural. A rede gerada nesse passo realiza a mesma classificação que as regras em que lhe deram origem.
O segundo algoritmo do KBANN, denominado \emph{Neural Learning}, refina a rede utilizando o algoritmo de aprendizagem \emph{backpropagation}. Segundo Towell \textit{et al.} (1990), apesar de todos testes utilizarem retro-propagação, qualquer método aprendizado supervisionado funcionaria. Embora o mecanismo de aprendizagem seja essencialmente uma retro-propagação padrão, a rede que está sendo treinada não segue o padrão de uma rede MLP com pesos aleatórios. Em vez disso, o primeiro algoritmo do KBANN constrói e inicializa a rede com pesos e bias pré-determinados Isso tem implicações diretas para o treinamento. Ao concluir essa etapa, a rede treinada pode ser utilizada como um classificador muito preciso. A subseção 2.3.1.1 apresenta como o conhecimento prévio é inserido na RNA.

\subsubsection{Inserção de Conhecimento em uma RNA}

Segundo Towell (1990), o primeiro passo do KBANN de mapear um conjunto de regras aproximadamente corretas em uma rede neural baseada no conhecimento. As regras a serem traduzidas em redes KBANN são expressas através de cláusulas Horn. Existem duas restrições no conjunto de regras. Primeiro, as regras devem ser proposicionais. Essa restrição resulta do uso de algoritmos de aprendizado neural que, no momento, são incapazes de manipular variáveis de cálculo de predicado. Em segundo lugar, as regras devem ser acíclicas. Essa restrição sem ciclos simplifica o treinamento das redes resultantes. No entanto, ele não representa uma limitação fundamental no KBANN, pois existem algoritmos baseados em \emph{backpropagation} que podem ser utilizados para treinar redes com ciclos (TOWELL \textit{et al.}, 1990).
Além dessas restrições, os conjuntos de regras fornecidos ao KBANN são hierarquicamente estruturados. Ou seja, as regras geralmente não mapeiam diretamente as entradas para as saídas. Em vez disso, pelo menos algumas das regras fornecem conclusões intermediárias que descrevem informações úteis ao usuário. Essas conclusões intermediárias podem ser utilizadas por outras regras para determinar a conclusão final ou outras conclusões intermediárias. É a estrutura hierárquica de um conjunto de regras que cria características derivadas para uso pelo sistema de aprendizagem baseado em exemplo. Assim, se o conhecimento de domínio não é hierarquicamente estruturado, então as redes criadas pelo KBANN não terão recursos que indicam dependências contextuais ou outras conjunções úteis dentro das descrições do exemplo. Além disso, uma rede KBANN que resulta da tradução de um conjunto de regras sem conclusões intermediárias poderia utilizar apenas uma rede \emph{Perceptron} para resolução do problema. A Tabela \ref{tab:tabelaKBANN}, mostra um resumo de como é mapeado a teoria de domínio em uma rede neural de KBANN.

\begin{table}[h]
	\centering
	\caption{Correspondências entre bases de conhecimento e redes neurais}
	\vspace{0.5cm}
	\label{tab:tabelaKBANN}
	\begin{tabular}{l|ll}
			\hline 
		Conhecimento base & $\Longleftrightarrow$  & Rede Neural \\ 
		\hline                               % para uma linha horizontal
		Conclusões finais &   $\Longleftrightarrow$    & Unidades de saída \\
		Suporte aos fatos & $\Longleftrightarrow$  & Unidades de entrada \\
		Conclusões intermediárias &   $\Longleftrightarrow $   & Unidades ocultas \\
		Dependências &   $\Longleftrightarrow$   & Conexões dos pesos
	\end{tabular}
\end{table}
 \vspace{-1.2em}
\centerline{Fonte: Towell, 1990}

\subsubsection{Algoritmo de Tradução de Regras}

Nessa subseção, é descrito, em detalhes, cada uma das sete etapas desse algoritmo. 

\textbf{1. Reescrever} - A primeira etapa do algoritmo transforma o conjunto de regras em um formato que esclarece sua estrutura hierárquica, e torna possível traduzir diretamente as regras em uma rede neural. Se houver mais de uma regra para um consequente, então cada regra para esse consequente com mais de um antecedente é re-escrita em duas regras. Uma dessas regras tem o consequente original e um único termo recém-criado como antecedente. A outra regra tem o termo recém-criado como seu consequente e os antecedentes da regra original como seus antecedentes. Por exemplo, a Figura \ref{fig:reescrita} mostra a transformação de duas regras no formato requerido pelas próximas etapas do KBANN. O trabalho de Towell \textit{et al.} (1990) explica a necessidade de se aplicar essa reescrita.

\begin{figure}[H] 
	\begin{center}
		\caption{Eliminação de disjunções com mais de um antecedente}
		\includegraphics[scale=0.5]{imagens/reescrita.png}
		\label{fig:reescrita}
		\centerline{Fonte: Towell, 1990}
	\end{center} 
\end{figure}


\textbf{2. Mapeamento} - Na segunda etapa do algoritmo, o KBANN estabelece um mapeamento entre um conjunto transformado de regras e uma rede neural. Usando esse mapeamento, mostrado na Tabela \ref{tab:tabelaKBANN}, o KBANN cria uma rede neural que têm uma correspondência um para um de acordo com o conjunto de regras. Tanto os pesos sinápticos como os bias são definidos de modo que consiga representar as regras estabelecidas no domínio inicial, ou seja, dado um cojnunto de entradas para o modelo de regras, a resposta gerada deve ser idêntica a resposta da rede neural. Ao concluir essa etapa, a rede do KBANN tem as informações do conjunto de regras relativas as entradas. No entanto, não há nenhuma garantia de que o conjunto de regras se refere de forma correta as infomações a ela apresentada. Assim, as quatro etapas seguintes aumentam confiabilidade da rede do KBANN com o aumento das ligações sinápticas, unidades de entrada e (possivelmente) unidades ocultas.

\textbf{3. Numeração} -  Nessa etapa, KBANN enumera as unidades nas redes KBANN por nível. Esse número influência diretamente nas etapas seguintes. O KBANN define o nível de cada unidade como sendo o comprimento do caminho mais longo para a unidade de saída.

\textbf{4. Adicionando unidades ocultas} - Esse passo adiciona unidades ocultas a rede KBANN, dando assim, a rede a capacidade de aprender características derivadas que foram não especificadas no conjunto de regras inicial. A etapa é opcional, pois as regras iniciais geralmente fornecem um vocabulário suficiente para evitar a necessidade de adicionar unidades ocultas. As unidades ocultas são adicionadas somente para complementar possíveis instruções que algum usuário do sistema acredite que seja últil futuramente. Nessa etapa deve-se especificar a quantidade e o local (níveis) das unidades adicionadas. 

\textbf{5. Adicionando unidades de entrada} - Nessa etapa, o KBANN aumenta sua rede com unidades de entrada não mencionados pelo conjunto de regras, mas que um especialista do domínio acredita serem relevantes. Essa adição é necessária porque um conjunto de regras que não é perfeitamente correto pode não identificar cada recurso de entrada necessário para aprender corretamente um conceito.

\textbf{6. Adicionando links} - No penúltimo passo, o algoritmo adiciona links com peso próximo a zero na rede utilizando a numeração das unidades estabelecidas na etapa 4. Conexões são adicionados para conectar cada unidade de uma camada $n$ a uma camada imediatamente seguinte, $n + 1$. 

\textbf{7. Perturbação}. O passo final na tradução de rede para regras é perturbar todos os pesos na rede adicionando um pequeno número aleatório a cada peso. Essa perturbação é muito pequena para ter um efeito nos cálculos da rede KBANN antes do treinamento. No entanto, é suficiente para evitar problemas causados pela simetria.

\subsubsection{Exemplo do algoritmo}

A Figura \ref{fig:algoritmoKbann} mostra uma tradução passo a passo de um conjunto simples de regras para uma rede KBANN. O painel $a$ mostra um conjunto de regras na notação Prolog. O painel \emph{b} é o mesmo conjunto de regras depois de terem sido re-escritos na etapa 1 do algoritmo de tradução. As únicas regras afetadas pela reescrita são duas que, juntas, formam uma definição disjuntiva do consequente $B$.

\begin{figure}[H] 
	\begin{center}
		\caption{Demonstração do algoritmo de KBANN}
		\includegraphics[scale=0.5]{imagens/algoritmoKbann.png}
		\label{fig:algoritmoKbann}
		\centerline{Fonte: Towell, 1990}
	\end{center} 
\end{figure}


O painel \emph{c} é uma representação gráfica das regras no painel \emph{b} que mostra a estrutura hierárquica das regras. Na Figura \ref{fig:algoritmoKbann}, as linhas pontilhadas representam antecedentes negados, enquanto as linhas contínuas e sólidas representam antecedentes não negados. 

A próxima etapa do algoritmo de tradução é criar uma rede neural mapeando a estrutura hierárquica das regras. Como resultado, há pouca diferença visual entre as representações da inicial rede KBANN no painel \emph{d} e a estrutura hierárquica das regras no painel \emph{c}.
Os painéis \emph{e} e \emph{f} ilustram o processo pelo qual as ligações, unidades de entrada e unidades ocultas não especificadas no conjunto de regras são adicionadas à rede. O painel \emph{e} mostra unidades na rede numeradas pelo seu nível. Além disso, o painel \emph{e} mostra uma unidade oculta (sombreada) adicionada à rede no nível 1 (um). 
O painel \emph{f} mostra a rede depois de novas ligações sinápticas entre os neurônios já pertencentes a rede à aqueles que foram adicionados posteriomente (passo 3), novas unidades de entrada e oculta. Essas novas ligações entre os neurônios é realizada de forma fraca, ou seja, com pesos próximos a zero. 
O último passo não foi demonstrado através de uma ilustração do algoritmo de tradução de regras para rede, porque a perturbação dos pesos de ligação resulta apenas em alterações dos valores dos pesos.

%As correntes de pensamento que se cristalizaram em torno da IA já estavam em gestação desde os anos 30 [BF81]. No entanto, oficialmente, a IA nasceu em 1956 com uma conferência de verão em Dartmouth College, NH, USA. Na proposta dessa conferência, escrita por John McCarthy (Dartmouth), Marvin Minsky (Hardward), Nathaniel Rochester (IBM) e Claude Shannon (Bell Laboratories) e submetida à fundação Rockfeller, consta a intenção dos autores de realizar ?um estudo durante dois meses, por dez homens, sobre o tópico inteligência artificial''. Ao que tudo indica, esta parece ser a primeira menção oficial à expressão ?Inteligência Artificial'' [McC79]. Desde seus primórdios, a IA gerou polêmica, a começar pelo seu próprio nome, considerado presunçoso por alguns, até a definição de seus objetivos e metodologias. O desconhecimento dos princípios que fundamentam a inteligência, por um lado, e dos limites práticos da capacidade de processamento dos computadores, por outro, levou periodicamente a promessas exageradas e às correspondentes decepções.

%Existem duas linhas principais de pesquisa para a construção de sistemas inteligentes: a linha conexionista e a linha simbólica .

%Conexionista visa à modelagem da inteligência humana através da simulação dos componentes do cérebro, isto é, de seus neurônios, e de suas interligações. Esta proposta foi formalizada inicialmente em 1943, quando o neuropsicólogo McCulloch e o lógico Pitts propuseram um primeiro modelo matemático para um neurônio. Um primeiro modelo de rede neuronal , isto é, um conjunto de neurônios interligados, foi proposto por Rosenblatt. Este modelo, chamado Perceptron , teve suas limitações demonstradas por Minsky e Papert [MP69] em livro onde as propriedades matemáticas de redes artificiais de neurônios são analisadas. Durante um longo período essa linha de pesquisa não foi muito ativa, mas o advento dos microprocessadores, pequenos e baratos, tornou praticável a implementação de máquinas de conexão compostas de milhares de microprocessadores, o que, aliado à solução de alguns problemas teóricos importantes, deu um novo impulso às pesquisas na área. O modelo conexionista deu origem à área de redes neuronais artificiais.

%Simbólica segue a tradição lógica e teve em McCarthy e Newell seus principais defensores. Os princípios dessa linha de pesquisa são apresentados no artigo Physical symbol systems de Newell [New80]. O sucesso dos sistemas especialistas (SE) (do inglês, ?expert system''), a partir da década de setenta, estabeleceu a manipulação simbólica de um grande número de fatos especializados sobre um domínio restrito como o paradigma corrente para a construção de sistemas inteligentes do tipo simbólico. Para facilitar a apresentação, vamos dividir a história da IA simbólica em ?épocas'', conforme proposto em relatórios internos do MIT (Massachusetts Institute of Technology)

\subsection{Top-Gen}

O TopGen utiliza o algoritmo de tradução de regras do KBANN (discutido na seção anterior) para definir uma topologia inicial de rede neural. Esse algoritmo realiza uma pesquisa heutística com as possíveis maneiras de adicionar um neurônio à rede, tentando encontrar a melhor topologia que refine a teoria do domínio inicial. Resumidamente, o TopGen procura neurônios na rede com altas taxas de erro e, em seguida, adiciona novos neurônios a essas regiões da rede.
A Figura \ref{fig:AlgoritmoTopGen} (Apêndice A) resume o algoritmo TopGen. O algoritmo utiliza dois conjuntos de validação, um para avaliar as diferentes topologias de rede e, um segundo para ajudar a decidir onde novos neurônios devem ser adicionados (o segundo conjunto de validação também é utilizado para decidir quando parar de treinar as novas redes encontradas). Essa rede é treinada utilizando \emph{backpropagation} e é colocada em uma lista, chamada de \emph{Open}. Em cada ciclo, o TopGen busca a melhor rede na lista (conforme medido pelo segundo conjunto de validação), e decide as possíveis maneiras de adicionar novos neurônios, em seguida treina essas novas redes e as coloca na lista \emph{Open}. Esse processo é repetido até atingir um dos seguintes critérios: (a) uma precisão de 100\% em relação ao segundo conjunto de validação ou (b) um limite de épocas previamente estabelecido.

\subsubsection{Localização de Novos Neurônios}

De acordo com o algoritmo (Apêndice A), a primeira etapa que deve ser realizada é localizar os neurônios da rede neural com altas taxas de erros. Isso é feito através de um conjunto de validação que será utilizado para incrementar os contadores que cada neurônio possui. Esses contadores indicam a taxa de erro que cada unidade contrubui para um possível resultado errado na saída da rede. Os contadores são definidos como : falsos positivos (FP) e falsos negativos (FN). Eles são incrementados de acordo com a saída individual de cada neurônio e não apenas em relação a saída final da rede. Para uma melhor compreensão, um exemplo de um falso negativo é se a saída do neurônio for incorretamente classificada como exemplo negativo, enquanto um falso positivo é um classificado incorretamente como um exemplo positivo. O TopGen incrementa os contadores de acordo com a quantidade de vezes que foi alterando o valor lógico de saída de um neurônio, levando a um exemplo mal classificado a ser classificado corretamente. Ou seja, se um neurônio estiver ativo para um exemplo errado, e alterar sua saída para ser inativo, e assim classificando de maneira correta o exemplo apresentado, isso fará que o contador de falsos positivos do neurônio seja incrementado. O contador de falsos negativos de um neurônio é incrementado seguindo o mesmo raciocínio. As novas redes serão geradas para tentar diminuir ou até mesmo eliminar o problema de cada neurônio, sendo que esse novo neurônio poderá também ajudar na redução de falsos negativos e positivos dos demais neurônios. Os novos neurônios são adicionados com base no tipo de contador (isto é, um contador falso negativo ou falso positivo) e o tipo de neurônio (isto é, um \emph{AND} ou \emph{OR}). Para um neurônio entender o seu comportamento, ou seja, a forma de receber as informações e lidar com elas na forma de um conector do tipo \emph{AND} ou \emph{OR} é realizado uma busca na base de regras iniciais e através dela é determiando como o neurônio deve se comportar. Na próxima subseção será detalhado como os neurônios são adicionados.

\subsubsection{Como Novos Neurônios são Adicionados}

Uma vez estimado onde se deve adicionar novos neurônios, é necessário saber como adicionar esses neurônios. TopGen faz a suposição de que, ao treinar uma de suas redes, o significado de um neurônio não mude significativamente. Fazer essa suposição permite alterar a rede de uma forma semelhante ao de refinar regras simbólicas. Towell \textit{et al.} (1990) mostrou que era válido fazer uma suposição semelhante sobre as redes de KBANN. A Figura \ref{fig:topGenNos} mostra as possíveis formas de como o TopGen adiciona neurônios a uma rede. Em uma base de regra simbólica que possui muitos falsos negativos, é possível diminuí-los descartando antecedentes de regras existentes ou adicionando novas regras para a base original.

 Como o KBANN é eficiente quando se remove antecedentes das regras existentes, o TopGen adiciona neurônios, destinados a diminuir falsos negativos, de uma forma que é análoga à adição de uma nova regra à base de regras (Shavlik, 1995). Se o neurônio existente for um neurônio do tipo \emph{OR}, o TopGen adicionará um novo neurônio como seu filho (Figura \ref{fig:topGenNos}a) e conectará totalmente esse novo neurônio com as unidades de entrada. Se o neurônio existente for um neurônio do tipo \emph{AND}, o TopGen cria um novo neurônio \emph{OR} que é o pai do neurônio \emph{AND} original e outro novo neurônio que é conectado totalmente às entradas (Figura \ref{fig:topGenNos}c). O TopGen move as conexões de saída do neurônio original (Figura \ref{fig:topGenNos}c) para se tornar as conexões de saída do novo neurônio \emph{OR}. Em uma base de regras simbólica, pode-se diminuir falsos positivos adicionando antecedentes a regras existentes ou removendo regras da base de regra (Shavlik, 1995). As Figuras \ref{fig:topGenNos}b e \ref{fig:topGenNos}d mostram os modos (analogamente às Figuras \ref{fig:topGenNos}a e \ref{fig:topGenNos}c explicadas acima) de adicionar antecedentes. Ao permitir essas adições, o TopGen é capaz de adicionar regras cujos consequentes não foram previamente definidos na base de regra. O TopGen manipula neurônios que não são \emph{AND} nem \emph{OR}, decidindo se esse neurônio está mais próximo de um neurônio \emph{AND} ou de um neurônio \emph{OR} (observando o bias do neurônio e os pesos de entrada).
 
 \begin{figure}[H] 
 	\begin{center}
 		\caption{Formas possíveis para adicionar novos neurônios. Arcos indicam conexões do tipo \emph{AND}}
 		\includegraphics[scale=0.5]{imagens/topGenNos.png}
 		\label{fig:topGenNos}
 		\centerline{Fonte: Shavlik, 1995}
 	\end{center} 
 \end{figure}

Depois que os novos neurônios são adicionados, o TopGen realiza o treinamento da rede pelo algoritmo do \emph{backpropagation}. Embora é desejado que os novos pesos representem a maior parte do erro, também se espera que os pesos antigos sejam alterados, se necessário. Ou seja, é necessário que os pesos antigos retenham o que aprenderam anteriormente, enquanto ao mesmo tempo se movem de acordo com a mudança de erro causada pela adição do novo neurônio. 

Segundo Shavlik (1995), para resolver esse problema, o TopGen multiplica as taxas de aprendizagem de pesos existentes por uma quantidade constante ($<= 1$) cada vez que novos neurônios são adicionados, produzindo um declínio exponencial das taxas de aprendizagem. Não é desejável mudar a teoria do domínio, a menos que haja considerável evidência de que ela está incorreta. Ou seja, há um termo entre a mudança da teoria do domínio e desconsiderando os exemplos de treinamento não classificados com ruído. Uma forma minimizar esse problema, é utilizar um regulador de decaimento de peso (Hinton, 1986). Pesos que fazem parte do domínio original da teoria, tem um decaimento em direção ao seu valor inicial, enquanto outros pesos decaem em direção a zero. 

O termo de decaimento foi proposto por Rumelhart \textit{et al.} (1986). A ideia do decréscimo de peso é adicionar, à função de custo usual, um termo que mede a distância de cada peso de seu valor inicia, e pode ser encontrado da seguinte forma:

\begin{align}
Custo = \sum_{k \in T}{(SaidaAlvo_k - SaidaRede_k)}^2 + \lambda \sum_{i \in C} \frac{{(w_i - w_{inicial})}^2}{1 + {(w_i - w_{inicial})}^2}
\end{align}

O primeiro termo da equação 2.15 soma todos os exemplos de treino \emph{T}, enquanto o segundo termo soma todas as conexões \emph{C}. O regulador entre o desempenho ea distância dos valores iniciais é ponderado por $\lambda$.

\subsubsection{Exemplo do TopGen}

Suponha que a teoria do domínio da Figura \ref{fig:topGenEx} também deveria incluir a seguinte regra:
%$B: -: \no F, G, H$.
Embora se tenha treinado a rede KBANN mostrada na Figura \ref{fig:topGenNos}c com todos os exemplos possíveis, foi incapaz de aprender o conceito correto.

\begin{figure}[H] 
	\begin{center}
		\caption{Tradução das regras em uma rede KBANN}
		\includegraphics[scale=0.5]{imagens/topGenExemplo.png}
		\label{fig:topGenEx}
		\centerline{Fonte: Shavlik, 1995}
	\end{center} 
\end{figure}

O TopGen começa treinando a rede na \ref{fig:topGenEx}c, obtendo nenhuma melhoria na base de regra original. Em seguida, prossegue tomando exemplos mal classificados do primeiro conjunto de validação para encontrar lugares onde pode ser benéfico adicionar neurônios. O exemplo a seguir da categoria A é classificado incorretamente pela teoria de domínio:
\newline \newline
\centerline{$not D \wedge E \wedge F \wedge  G \wedge not H \wedge not I \wedge J \wedge K$}
\newline

Enquanto o neurônio \emph{C} (Figura \ref{fig:topGenEx}c) foi corretamente classificado como falso nesse exemplo, o neurônio \emph{B} é incorretamente falso. \emph{B} é falso, uma vez que \emph{B1} e \emph{B2} também são falsos. Se \emph{B} tivesse sido verdadeiro, esse exemplo teria sido classificado corretamente (já que \emph{C} é correto). Nesse caso, o TopGen incrementa o contador de falso-negativo do B. Além disso, o algoritmo também incrementa os contadores de \emph{B1}, \emph{B2} e \emph{A}, utilizando argumentos semelhantes.
Os neurônios \emph{B1}, \emph{B2}, \emph{B} e \emph{A} terão todos os contadores de falso-negativo com alta taxas de erro após todos os exemplos serem processados. Devido a um grande de erros, o TopGen considera a adição de neurônios \emph{OR} aos neurônios \emph{A}, \emph{B1} e \emph{B2}, como feito na Figura \ref{fig:topGenEx}, e também considera a adição de outra disjunção, análogo à Figura \ref{fig:topGenEx}a, ao neurônio B. Qualquer um dessas correções permite que a rede aprenda o conceito desejado. Como o TopGen prefere os neurônios mais distantes do neurônio de saída, então será adicionado em \emph{B1} ou \emph{B2}.


%%\subsection{Sensores tolerantes a falhas} 
%
%%\begin{figure}[H]
%%\begin{center}
%%\includegraphics[scale=0.95]{imagens/etapasdiagn.png}
%%\end{center}
%%\caption{Etapas diagnóstico de falhas.}
%%\label{Fig:etapasdiagn}
%%\end{figure}
